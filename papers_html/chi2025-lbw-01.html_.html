




<!DOCTYPE html>






    










<html lang="en"
      
        
      
      
        

        

        
        
            
        
        
        
        
        

      class="pb-page"
         data-request-id="99b3745a0064e879-SJC"  

>

    
        <head data-pb-dropzone="head">
            

<meta charset="UTF-8">






    
        
            
        
    
        
            
        
    
        
            
        
    
        
            
                
                
<title>"A Great Start, But...": Evaluating LLM-Generated Mind Maps for Information Mapping in Video-Based Design | Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems</title>





                
            
        
    
        
            
        
    







    
        
            
        
    
        
            
        
    
        
            
                
                



                
            
        
    
        
            
        
    
        
            
        
    










    <link rel="stylesheet" href="/products/acm/releasedAssets/css/build-045d25f198b34dc1d89d.css"/><link rel="stylesheet" href="/products/acm/releasedAssets/css/print-045d25f198b34dc1d89d.css" media="print"/>


















    
        
            
                
                
                
                    
                    <link rel="schema.DC" href="http://purl.org/DC/elements/1.0/"></link><meta name="dc.Format" content="text/HTML"></meta><meta name="dc.Identifier" scheme="acm-id" content="3719940"></meta><meta name="dc.Identifier" scheme="doi" content="10.1145/3706599.3719940"></meta><meta name="dc.Identifier" scheme="article-no" content="1"></meta><meta name="dc.Language" content="EN"></meta><meta name="dc.Coverage" content="world"></meta>




<link rel="meta" type="application/atom+xml" href="https://doi.org/10.1145%2F70609.70628"></link>
<link rel="meta" type="application/rdf+json" href="https://doi.org/10.1145%2F70609.70628"></link>
<link rel="meta" type="application/unixref+xml" href="https://doi.org/10.1145%2F70609.70628"></link>


                    
                
            
        
    
        
            
                
                
                
                    
                    

<style id="pb-theme">
.theme {

}
</style>
                    
                
            
        
    
        
            
                
                
                
                
                
            
        
    
        
            
                
                
                
                
                
            
        
    
        
            
                
                
                
                    
                    <meta name="robots" content="noarchive"/>















    
        <meta property="og:title" content=""A Great Start, But...": Evaluating LLM-Generated Mind Maps for Information Mapping in Video-Based Design | Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems"/>
    
    



    
        <meta property="og:type" content="Chapter"/>
    
    



    
        <meta property="og:url" content="https://dl.acm.org/doi/10.1145/3706599.3719940"/>
    
    


    
        <meta property="og:image" content="https://dl.acm.org/cms/asset/9ff8084f-ead3-4316-a709-04124a22e308/3706599.cover.jpg" />
        
            <meta property="og:image:width" content="550" />
            <meta property="og:image:height" content="711" />
        
    
    



    
        <meta property="og:site_name" content="ACM Conferences"/>
    
    



    
    



<meta name="viewport" content="width=device-width,initial-scale=1"><meta name="publication_doi" content="10.1145/3706599.3719940"/>


    















                    
                
            
        
    




<meta http-equiv="X-UA-Compatible" content="IE=edge">
<link rel="stylesheet" href="/pb-assets/styles/acm-custom-1743623214337.css">
<link rel="stylesheet" href="/pb-assets/styles/journals-colors-1754938992547.css">
<link rel="stylesheet" href="/pb-assets/styles/conferences-colors-1729017983273.css">
<link rel="stylesheet" href="/pb-assets/styles/magazines-colors-1728490688780.css">
<link rel="stylesheet" href="/pb-assets/styles/sigs-colors-1743023035813.css">
<script defer src="https://scholar.google.com/scholar_js/casa.js" async nonce="99b3745a0064e879-SJC"></script>
<script id="Cookiebot" src="https://consent.cookiebot.com/uc.js" data-cbid="d5e9e377-b0f2-49fd-b006-d86d5073d17e" data-blockingmode="auto" type="text/javascript" nonce="99b3745a0064e879-SJC"></script>
<link rel="apple-touch-icon" sizes="180x180" href="/pb-assets/head-metadata/apple-touch-icon-1574252172393.png">
<link rel="icon" type="image/png" sizes="32x32" href="/pb-assets/head-metadata/favicon-32x32-1574252172003.png">
<link rel="icon" type="image/png" sizes="16x16" href="/pb-assets/head-metadata/favicon-16x16-1574252172937.png">
<link rel="manifest" href="/pb-assets/head-metadata/site-1574252171130.webmanifest" crossorigin="use-credentials">
<link rel="mask-icon" href="/pb-assets/head-metadata/safari-pinned-tab-1574252171193.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#00a300">
<meta name="theme-color" content="#ffffff">
<script defer src="https://static.cloudflareinsights.com/beacon.min.js/v652eace1692a40cfa3763df669d7439c1639079717194" integrity="sha512-Gi7xpJR8tSkrpF7aordPZQlW2DLtzUlZcumS8dMQjwDHEnw9I7ZLyiOj/6tZStRBGtGgN6ceN6cMH8z7etPGlw==" data-cf-beacon='{"rayId":"6e539318ac0a38db","token":"b7f168b3cd354a55a4dd51b513830799","version":"2021.12.0","si":100}' crossorigin="anonymous" nonce="99b3745a0064e879-SJC"></script>
<script defer src="https://static.cloudflareinsights.com/beacon.min.js/v8b253dfea2ab4077af8c6f58422dfbfd1689876627854" integrity="sha512-bjgnUKX4azu3dLTVtie9u6TKqgx29RBwfj3QXYt5EKfWM/9hPSAI/4qcV5NACjwAo8UtTeWefx6Zq5PHcMm7Tg==" data-cf-beacon='{"rayId":"7f51c78ba8dacf41","token":"3bb0add5452d43a2b5d4b3d6c628944c","version":"2023.8.0","si":100}' crossorigin="anonymous" nonce="99b3745a0064e879-SJC"></script>
<!-- Google Tag Manager -->
    <script nonce="99b3745a0064e879-SJC">(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;var n=d.querySelector('[nonce]');n&&j.setAttribute('nonce',n.nonce||n.getAttribute('nonce'));f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-NFGCMX');</script>
    <!-- End Google Tag Manager -->






<meta name="pbContext" content=";topic:topic:conference-collections&gt;chi;taxonomy:taxonomy:conference-collections;wgroup:string:ACM Publication Websites;issue:issue:doi\:10.1145/3706599;groupTopic:topic:acm-pubtype&gt;proceeding;ctype:string:Book Content;subPage:string:Full Text;article:article:doi\:10.1145/3706599.3719940;page:string:Article/Chapter View;csubtype:string:Conference Proceedings;website:website:dl-site;journal:journal:acmconferences;pageGroup:string:Publication Pages">
        </head>
    

    



    
        
        
        
            <body
                    class="pb-ui website-dl-site">
            






    
    
        

<!-- Google Tag Manager (noscript) -->
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NFGCMX" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager (noscript) -->









<a href="#skip-to-main-content" class="sr-only-focusable">skip to main content</a>

        <div id="pb-page-content" data-ng-non-bindable>
                
            <div data-pb-dropzone="main" data-pb-dropzone-name="Main">
                
                    
                        



        
        









    
    
        <header data-widget-def="ux3-layout-widget" data-widget-id="88f434fd-b4d9-4f0e-b7b6-cde0fadcc9ef" class="header base chi">
        



        
        <div class="header__fixed-items fixed fixed-element">









    
    
        <div data-widget-def="ux3-layout-widget" data-widget-id="c844bab8-b1d5-4df4-8bea-71f6156459e4" class="container header--first-row">
        



        
        <nav class="pull-left">



        
        <ul class="rlist--inline">
    <li class="header__logo1">
        <a href="/" title="">
            <img alt="ACM Digital Library home" src="/specs/products/acm/releasedAssets/images/acm-dl-logo-white-1ecfb82271e5612e8ca12aa1b1737479.png" loading="eager">
        </a>
    </li>
    <li class="header__logo2 hidden-xs">
        <a href="https://www.acm.org" title="external site link">
            <img alt="ACM Association for Computing Machinery corporate logo" src="specs/products/acm/releasedAssets/images/acm-logo-1.png" loading="eager">
        </a>
    </li>
</ul> 
</nav><div class="pull-right">









    
    
        <nav data-widget-def="ux3-layout-widget" data-widget-id="ab4ba9a1-6e57-4b90-b9c2-fc7914d9a3a1" class="header__quick-menu text-onDark">
        



        
        <ul class="rlist--inline"><li class="advanced-search-link hidden-lg hidden-md hidden-sm">



        
        <a href="/search/advanced" >Advanced Search</a>
</li><li class="show-on-mobile">



        
        <a href="/browse/" title="browse the Digital Library by publication title or publisher">Browse</a>
</li><li class="show-on-mobile">



        
        <a href="/about" title="About the ACM Digital Library">About</a>
</li><li class="login-list">



        
        




    








    
    
        












<div class="loginBar login-open">
    
        
        
            <ul class="rlist--inline">
                <li class="login-link">
                    
                        
                        
                            <a href="/action/showLogin?redirectUri=%2Fdoi%2F10.1145%2F3706599.3719940">
                                Sign in
                            </a>
                        
                    
                </li>
                
                    <li class="register-link">
                        <a href="https://accounts.acm.org?redirectUri=%2Fdoi%2F10.1145%2F3706599.3719940" class="btn" title="Register">
                            Register
                        </a>
                    </li>
                
            </ul>
        
    
</div>
    


</li></ul>

        </nav>
    

</div>

        </div>
    











    
    
        <div data-widget-def="menuWidget" data-widget-id="13da1316-80a7-4370-a291-8968cd9cb35e" class="container header--second-row">
        



        
        <div class="responsive-menu-container clearfix"><div class="left-section pull-left"></div><div class="menu-section"><div class="main-nav responsive-menu-nav"><a href="#global-menu" data-target="global-menu" data-toggle="nav" title="menu drawer"><span class="drawer__icons-box"><span class="drawer__icons-controls"></span></span></a><nav role="navigation" id="global-menu" data-ctrl-res="screen-sm" aria-label="Main Navigation" class="drawer__nav container gutterless hidden-sm hidden-xs"><div class="menu-login-items hidden-md hidden-lg"></div><ul id="menubar" class="menubar rlist--inline"><li id="menu-item-global-menu-0" class="menu-item mobile-menu-item"><a href="/search/advanced"><span>Advanced Search</span></a></li><li id="menu-item-global-menu-1" class="menu-item"><a href="/journals"><span>Journals</span></a></li><li id="menu-item-global-menu-2" class="menu-item"><a href="/magazines"><span>Magazines</span></a></li><li id="menu-item-global-menu-3" class="menu-item"><a href="/proceedings"><span>Proceedings</span></a></li><li id="menu-item-global-menu-4" class="menu-item"><a href="/acmbooks"><span>Books</span></a></li><li id="menu-item-global-menu-5" class="menu-item"><a href="/sigs"><span>SIGs</span></a></li><li id="menu-item-global-menu-6" class="menu-item"><a href="/conferences"><span>Conferences</span></a></li><li id="menu-item-global-menu-7" class="menu-item"><a href="/people"><span>People</span></a></li><li class="hidden-lg hidden-md"><div data-toggle="transplant" data-target-class="hidden-xs hidden-sm" data-target=".header__quick-menu .show-on-mobile" data-direction="from" data-transplant="self"></div></li><li aria-haspopup="true" aria-label="More" class="dropdown-more hidden dropdown menu-parent"><a href="#" title="More" data-toggle="dropdown" class="dropdown__toggle"><span>More</span><i aria-hidden="true" class="icon-section_arrow_d pull-right hidden-sm hidden-xs"></i></a><ul aria-labelledby="main0-1" aria-hidden="true" class="rlist dropdown__menu"></ul></li><li class="menubar__extra-mob-links"></li></ul></nav><div id="menu-quick-search" data-db-target-of="menu-quick-search" class="hidden-md hidden-lg"><div class="menu-quick-search__wrapper"><div data-toggle="transplant" data-target-class="hidden-xs hidden-sm" data-target=".header--second-row .quick-search--form" data-direction="from" data-transplant="self" class="quick-search-mobile"></div></div></div></div></div><div class="right-section pull-right">



        
        <div class="quickSearchFormContainer"><div class="quick-search"><div aria-live="assertive" class="advanced-search__autocomplete__announcer sr-only"></div><div class="clearfix quick-search__clearfix"><form action="/action/doSearch" name="defaultQuickSearch" method="get" title="Quick Search" class="quick-search--form"><div class="quick-search--input"><div class="input-group option-0"><label for="AllFieldf73847c0-d936-48ec-9bf9-139b3828507f" class="sr-only">Search ACM Digital Library</label><input type="search" autocomplete="off" id="AllFieldf73847c0-d936-48ec-9bf9-139b3828507f" name="AllField" placeholder="Search ACM Digital Library" data-auto-complete-max-words="7" data-auto-complete-max-chars="32" data-contributors-conf="3" data-topics-conf="3" data-publication-titles-conf="3" data-history-items-conf="3" data-group-titles-conf="3" value="" class="auto-complete quick-search__input"/></div></div><div class="quick-search--button"><button type="submit" title="Search" aria-label="Search" class="btn quick-search__button icon-Icon_Search"><span class="sr-only">Search</span><span>Search</span></button></div></form></div>



        
        <a class="quick-search__advancedHeader" title="link to Advanced Search form" href="/search/advanced">Advanced Search</a>
</div></div>
</div></div><div class="header__dropzone"></div>

        </div>
    





        
        <span style="display: none;">10.1145/3706599.3719940</span><span style="display: none;">acmconferences</span><span style="display: none;">Article/Chapter View</span><span style="display: none;">Full Text</span><span style="display: none;">Publication Pages</span><span style="display: none;">chi</span><span style="display: none;">Conference Proceedings</span><span style="display: none;">conference-collections</span><div class="sub-nav fixed-element"><a href="#" data-db-target-for="sub-nav__items" data-more="false" data-lines="1" style="text-transform: uppercase;" class="sub-nav__toggle hidden-lg truncate-text-css">chi</a><div class="sub-nav__container"><div class="container"><div data-ctrl-res="screen-md" class="responsive-menu-container"><div class="left-section pull-left"></div><div class="menu-section"><div style="display: block" class="responsive-menu-nav"><nav id="sub-nav__items" data-db-target-of="sub-nav__items" class="sub-nav__holder drawer__nav"><ul class="rlist--inline menubar"><li><a href="/conference/chi" class="sub-nav__item">Conference</a></li><li><a href="/conference/chi/proceedings" class="sub-nav__item">Proceedings</a></li><li><a href="/conference/chi/upcoming" class="sub-nav__item">Upcoming Events</a></li><li><a href="/conference/chi/authors" class="sub-nav__item">Authors</a></li><li><a href="/conference/chi/affiliations" class="sub-nav__item">Affiliations</a></li><li><a href="/conference/chi/award-winners" class="sub-nav__item">Award Winners</a></li><li aria-haspopup="true" aria-label="More" class="dropdown-more hidden dropdown menu-parent"><a href="#" title="More" data-toggle="dropdown" class="dropdown__toggle hidden-md hidden-sm hidden-xs"><span>More</span><i aria-hidden="true" class="icon-section_arrow_d"></i></a><ul aria-labelledby="main0-1" aria-hidden="true" class="rlist dropdown__menu visible-md visible-sm visible-xs"></ul></li></ul></nav></div></div><div class="right-section hidden-md hidden-sm hidden-xs"></div></div></div></div><div class="hidden-xs hidden-sm"><div class="progress-bar--wrapper"><div style="width: 0.116818%;" class="progress-bar"></div></div></div></div>
</div><div></div><div class="banner conference-landing"></div><div class="header-breadcrumb"></div>

        </header>
    




                    
                        









    
    
        <div data-widget-def="ux3-layout-widget" data-widget-id="84fac94e-a290-4bf2-9ff9-7edc8316a494" id="skip-to-main-content">
        



        
        <main class="content chi loi-page no-margin">



        
        <div role="dialog" aria-labelledby="exportCitationsPopup" class="ux-modal-container"><div id="exportCitation" class="modal"><div class="modal__dialog"><div class="modal__header"><button type="button" data-dismiss="modal" class="close"><i aria-hidden="true" aria-label="close popup" class="icon-close_thin"></i></button><h2 id="exportCitationsPopup">Export Citations</h2></div><div class="modal__body"><div class="exportCitation__tabs"><div class="tab"><ul role="tablist" class="rlist tab__nav"></ul></div><div class="csl-wrapper copy__text-wrapper"><form action="/action/exportCiteProcCitation" method="post" target="_blank"><input type="hidden" name="content" value=""/><input type="hidden" name="dois" value=""/><input type="hidden" name="format" value=""/><fieldset class="input-group"><label for="citation-format" class="visibility-hidden">Select Citation format</label><select id="citation-format" data-csl-doi="10.1145/3706599.3719940" aria-label="Select Citation format"><option value="bibtex" data-format="bibTex">BibTeX</option><option value="endNote" data-format="endNote">EndNote</option><option value="acm" data-format="text">ACM Ref</option></select><span class="select-arrow"><i class="icon-bottom-arrow"></i></span></fieldset><ul class="rlist tab__content"><li id="allResultstab" aria-labelledby="allResults" role="tabpanel" class="tab__pane"><div class="all-results-tab-container"><div class="hidden warning-message mb-2">Please download or close your previous search result export first before starting a new bulk export.</div><div class="desc-text"><div class="bold">Preview is not available.</div>By clicking download,<b class="ml-1">a status dialog</b> will open to start the export process. The process may take<b class="ml-1">a few minutes</b> but once it finishes a file will be downloadable from your browser. You may continue to browse the DL while the export process is in progress.</div></div></li><li id="selectedTab" aria-labelledby="selected" role="tabpanel" class="tab__pane active"><div class="csl-wrapper copy__text-wrapper"><pre class="copy__text csl-response"></pre><div id="export-warning"></div><div class="pull-right"><ul role="menu" class="rlist--inline separator"><li><a href="javascript:void(0)" role="menuitem" title="Download citation" class="download__btn disabled"><label class="visibility-hidden">Download citation</label><i aria-hidden="true" class="icon-Icon_Download"></i></a></li><li><input type="hidden" id="doisLimitNumber" value="1000"/><a href="javascript:void(0)" role="menuitem" title="Copy citation" class="copy__btn disabled"><label class="visibility-hidden">Copy citation</label><i aria-hidden="true" class="icon-pages"></i></a></li></ul></div></div></li></ul></form></div></div></div></div></div></div>




        
        <link id="build-style-article" rel="stylesheet" type="text/css" href="/products/acm/releasedAssets/css/build-article-045d25f198b34dc1d89d.css"/><article xmlns="http://www.w3.org/1999/xhtml" data-design="pill" data-has="right-rail" data-theme="conference-proceedings" data-type="chapter" vocab="http://schema.org/" typeof="Chapter" lang="en" dir="ltr"><header data-extent="frontmatter"><div class="core-container">



        
        <style>
.article__breadcrumbs {
    line-height: 1rem;
    margin-bottom: 2rem;
}

.article__breadcrumbs {
    a:link, a:visited, a:hover, a:active {
        text-decoration: none;
        color: inherit!important;
    }
}
</style>




        
        



        
        <nav aria-label="Breadcrumbs" class="article__breadcrumbs separator"><ul><li><a href="https://dl.acm.org/" class="article__tocHeading">Home</a></li><li><a href="/conferences" class="article__tocHeading">Conferences</a></li><li><a href="/conference/chi" class="article__tocHeading">CHI</a></li><li><a href="/conference/chi/proceedings" class="article__tocHeading">Proceedings</a></li><li><a href="/doi/proceedings/10.1145/3706599" class="article__tocHeading">CHI EA '25</a></li><li><a href="/doi/10.1145/3706599.3719940" aria-current="page" class="article__tocHeading">&quot;A Great Start, But...&quot;: Evaluating LLM-Generated Mind Maps for Information Mapping in Video-Based Design</a></li></ul></nav>

<div data-article-access="free" data-article-access-type="free" class="meta-panel"><div class="meta-panel__left-content"><div class="meta-panel__type"><span>Work in Progress</span></div><div class="meta-panel__access meta-panel__access--free"><i aria-hidden="true" title="Free access" class="icon-lock_open"></i><span>Free access</span></div></div><div class="meta-panel__right-content"><div class="meta-panel__share">



        
        <!-- Go to https://www.addtoany.com/buttons/customize/ to customize your tools --><script type="text/javascript" defer="defer" src="https://static.addtoany.com/menu/page.js"></script><div class="share"><div class="share__block share__inline-links"><div class="pb-dropzone" data-pb-dropzone="shareBlock" title="shareBlock"></div><span class="sr-only">Share on</span><ul class="rlist--inline a2a a2a_kit a2a_kit_size_32"><li class="a2a_listitem_custom"><a role="link" title="share on X" class="a2a_button_x"><i aria-hidden="true" class="at-icon-wrapper icon-x"></i></a></li><li class="a2a_listitem_custom"><a role="link" title="share on LinkedIn" class="a2a_button_linkedin"><i aria-hidden="true" class="at-icon-wrapper icon-linkedin"></i></a></li><li class="a2a_listitem_custom"><a role="link" title="share on Reddit" class="a2a_button_reddit"><i aria-hidden="true" class="at-icon-wrapper icon-riddit-filled"></i></a></li><li class="a2a_listitem_custom"><a role="link" title="share on Facebook" class="a2a_button_facebook"><i aria-hidden="true" class="at-icon-wrapper icon-Icon_Facebook"></i></a></li><li class="a2a_listitem_custom"><a role="link" title="share via email" class="a2a_button_email"><i aria-hidden="true" class="at-icon-wrapper icon-Icon_mail"></i></a></li><div class="pb-dropzone" data-pb-dropzone="share-additional-links" title="share-additional-links"></div></ul></div></div>
</div></div></div><h1 property="name">"A Great Start, But...": Evaluating LLM-Generated Mind Maps for Information Mapping in Video-Based Design</h1><div class="core-relations my-3"></div><div class="contributors"><span class="authors"><span class="heading">Authors</span>: <span role="list"><span property="author" typeof="Person" role="listitem"><a href="#artseq-00001"><img src="/pb-assets/icons/DOs/default-profile-1543932446943.svg" class="core-profile-image" role="presentation" /><span property="givenName">Tianhao</span> <span property="familyName">He</span></a></span>, <span property="author" typeof="Person" role="listitem"><a href="#artseq-00002"><img src="/pb-assets/icons/DOs/default-profile-1543932446943.svg" class="core-profile-image" role="presentation" /><span property="givenName">Karthi</span> <span property="familyName">Saravanan</span></a></span>, <span property="author" typeof="Person" role="listitem"><a href="#artseq-00003"><img src="/action/showDoPubAsset?doi=10.1145/contrib-81548019687&amp;format=rel-imgonly&amp;assetId=evanpicsmall.png" class="core-profile-image" role="presentation" /><span property="givenName">Evangelos</span> <span property="familyName">Niforatos</span></a></span>, <span property="author" typeof="Person" role="listitem"><a href="#artseq-00004"><img src="/pb-assets/icons/DOs/default-profile-1543932446943.svg" class="core-profile-image" role="presentation" /><span property="givenName">Gerd</span> <span property="familyName">Kortuem</span></a></span></span></span><a href="#tab-contributors" class="to-authors-affiliations" data-id="article-authors-viewall">Authors Info &amp; Claims</a></div><div class="core-self-citation"><div property="isPartOf" typeof="Book"><a href="/doi/proceedings/10.1145/3706599" property="name">CHI EA '25: Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems</a></div><div data-type="acm-number">Article No.: 1, Pages <span property="pageStart">1</span> - <span property="pageEnd">7</span></div><div class="doi"><a href="https://doi.org/10.1145/3706599.3719940" property="sameAs">https://doi.org/10.1145/3706599.3719940</a></div></div><div class="core-published"><span class="label">Published</span>: <span class="core-date-published">25 April 2025</span> <a href="#core-history">Publication History</a><a data-target="crossmark" href="#" title="Check for updates on crossmark" data-doi="10.1145/3706599.3719940" data-id="article-info-crossmark" class="crossmark__link"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 290 58" height="27px" role="presentation"><path fill="url(#horizontal_crossmark)" stroke="#948F8F" stroke-miterlimit="10" stroke-width=".75" d="M287 1H3a2 2 0 0 0-2 2v52a2 2 0 0 0 2 2h284a2 2 0 0 0 2-2V3a2 2 0 0 0-2-2Z"></path><path fill="#535353" d="M80.3 23.58a6.395 6.395 0 0 0-.55-1.43 3.92 3.92 0 0 0-2.19-1.86 5.099 5.099 0 0 0-1.71-.29 5 5 0 0 0-2.46.58 4.831 4.831 0 0 0-1.69 1.54 6.921 6.921 0 0 0-1 2.19 10.16 10.16 0 0 0 0 5 6.921 6.921 0 0 0 1 2.19 4.83 4.83 0 0 0 1.69 1.5 5 5 0 0 0 2.46.58 4.44 4.44 0 0 0 1.85-.36 4.12 4.12 0 0 0 1.38-1c.39-.436.695-.942.9-1.49A7.094 7.094 0 0 0 80.4 29h3a8.46 8.46 0 0 1-.69 2.92 7.179 7.179 0 0 1-1.59 2.29 7 7 0 0 1-2.35 1.49 8.14 8.14 0 0 1-3 .52 8.43 8.43 0 0 1-3.59-.74 7.88 7.88 0 0 1-2.69-2 9.001 9.001 0 0 1-1.69-3 11.41 11.41 0 0 1 0-7.23 9.001 9.001 0 0 1 1.69-3 8.001 8.001 0 0 1 2.69-2 8.3 8.3 0 0 1 3.59-.75 9.44 9.44 0 0 1 2.83.41c.866.242 1.68.642 2.4 1.18A6.229 6.229 0 0 1 82.65 21a6.66 6.66 0 0 1 .78 2.58H80.3ZM85.9 17.9h2.85v6.63h.05a4.15 4.15 0 0 1 1.56-1.46 4.61 4.61 0 0 1 2.31-.59 4.83 4.83 0 0 1 3.33 1.1 4.21 4.21 0 0 1 1.22 3.3v8.88H94.4v-8.13a3.51 3.51 0 0 0-.65-2.21 2.36 2.36 0 0 0-1.87-.69 3.1 3.1 0 0 0-1.3.26 2.821 2.821 0 0 0-1 .73A3.41 3.41 0 0 0 89 26.8a3.88 3.88 0 0 0-.23 1.33v7.63H85.9V17.9ZM102.47 30c-.002.491.069.98.21 1.45.131.448.348.866.64 1.23a3.08 3.08 0 0 0 1.08.84 3.543 3.543 0 0 0 1.55.31 3.431 3.431 0 0 0 2-.54c.541-.402.94-.966 1.14-1.61h2.7A5.349 5.349 0 0 1 109.7 35a5.715 5.715 0 0 1-1.74.85 7 7 0 0 1-2 .29 6.848 6.848 0 0 1-2.7-.5 5.577 5.577 0 0 1-2-1.4A5.953 5.953 0 0 1 100 32a8.748 8.748 0 0 1-.41-2.75 7.768 7.768 0 0 1 .44-2.61 6.67 6.67 0 0 1 1.25-2.17 5.863 5.863 0 0 1 4.56-2 5.79 5.79 0 0 1 2.74.64c.783.41 1.466.986 2 1.69a6.824 6.824 0 0 1 1.16 2.41c.264.905.352 1.852.26 2.79h-9.53Zm6.65-1.87a4.605 4.605 0 0 0-.29-1.3c-.148-.4-.368-.77-.65-1.09a3.22 3.22 0 0 0-1-.75 3 3 0 0 0-1.31-.29 3.431 3.431 0 0 0-1.36.26 3.108 3.108 0 0 0-1 .73 3.594 3.594 0 0 0-.7 1.09 3.798 3.798 0 0 0-.29 1.35h6.65-.05ZM122.88 27.15a2.666 2.666 0 0 0-1-1.81 3.14 3.14 0 0 0-2-.61c-.4.005-.798.07-1.18.19-.435.136-.83.376-1.15.7a3.92 3.92 0 0 0-.87 1.43 6.783 6.783 0 0 0-.35 2.39c.002.539.065 1.076.19 1.6.113.509.316.993.6 1.43.273.41.635.752 1.06 1a3 3 0 0 0 1.58.39 2.872 2.872 0 0 0 2.06-.77 3.596 3.596 0 0 0 1-2.18h2.85a6.26 6.26 0 0 1-1.91 3.86 5.83 5.83 0 0 1-4 1.34 6.61 6.61 0 0 1-2.69-.51 5.695 5.695 0 0 1-2-1.4 6.001 6.001 0 0 1-1.21-2.11 8.279 8.279 0 0 1-.41-2.65 8.987 8.987 0 0 1 .4-2.72 6.237 6.237 0 0 1 1.2-2.21 5.614 5.614 0 0 1 2-1.47 6.7 6.7 0 0 1 2.79-.54 7.801 7.801 0 0 1 2.14.29 5.634 5.634 0 0 1 1.8.86c.529.386.969.88 1.29 1.45a5 5 0 0 1 .6 2.07h-2.85l.06-.02ZM128.13 17.9H131V28l5.15-5.22h3.5l-5 4.75 5.42 8.17h-3.47l-4-6.27-1.6 1.7v4.63h-2.85V17.9h-.02ZM147.15 22.83h2.13v-1.08a5.505 5.505 0 0 1 .3-2c.161-.456.436-.862.8-1.18.33-.273.721-.462 1.14-.55.44-.094.89-.141 1.34-.14a8.158 8.158 0 0 1 2 .18v2.24a4.113 4.113 0 0 0-.59-.11 6.343 6.343 0 0 0-.74 0 1.74 1.74 0 0 0-1 .27 1.204 1.204 0 0 0-.41 1.08v1.33h2.42V25h-2.42v10.8h-2.85V25h-2.12v-2.17ZM162.23 36.1a6.999 6.999 0 0 1-2.76-.51 5.877 5.877 0 0 1-2-1.41 5.998 5.998 0 0 1-1.33-2.18 8.775 8.775 0 0 1 0-5.48 6.008 6.008 0 0 1 1.27-2.15 5.894 5.894 0 0 1 2-1.41A7.71 7.71 0 0 1 165 23a5.894 5.894 0 0 1 2 1.41 6.003 6.003 0 0 1 1.28 2.15c.585 1.78.585 3.7 0 5.48a5.99 5.99 0 0 1-3.28 3.54 7.002 7.002 0 0 1-2.77.52Zm0-2.25a3.268 3.268 0 0 0 1.65-.4c.447-.262.83-.621 1.12-1.05.304-.444.528-.938.66-1.46a6.581 6.581 0 0 0 0-3.31 4.416 4.416 0 0 0-.66-1.46 3.526 3.526 0 0 0-1.15-1 3.6 3.6 0 0 0-3.3 0 3.526 3.526 0 0 0-1.15 1 4.414 4.414 0 0 0-.66 1.46 6.558 6.558 0 0 0 0 3.31c.132.522.356 1.016.66 1.46a3.47 3.47 0 0 0 1.15 1.05 3.26 3.26 0 0 0 1.68.4ZM171.13 22.83h2.67v2.5c.097-.362.264-.701.49-1 .251-.341.547-.647.88-.91a4.404 4.404 0 0 1 1.14-.66 3.41 3.41 0 0 1 1.28-.25c.23-.013.46-.013.69 0h.39v2.79l-.61-.09a5.173 5.173 0 0 0-.61 0 3.278 3.278 0 0 0-1.36.29 3.131 3.131 0 0 0-1.11.85 4.171 4.171 0 0 0-.75 1.39 6 6 0 0 0-.28 1.9v6.15h-2.85V22.83h.03ZM198.22 35.75h-2.8V34a3.907 3.907 0 0 1-1.56 1.56 4.25 4.25 0 0 1-2.11.59 4.742 4.742 0 0 1-3.75-1.31 5.537 5.537 0 0 1-1.12-3.84v-8.2h2.85v7.92a3.503 3.503 0 0 0 .65 2.4 2.38 2.38 0 0 0 1.83.7 3.599 3.599 0 0 0 1.5-.27 2.66 2.66 0 0 0 1-.74c.259-.326.444-.705.54-1.11a5.79 5.79 0 0 0 .16-1.4v-7.5h2.85v12.95h-.04ZM201.3 22.83h2.7v1.75a3.523 3.523 0 0 1 1.72-1.58 5.568 5.568 0 0 1 2.33-.49 6.17 6.17 0 0 1 2.66.54 5.246 5.246 0 0 1 1.89 1.47c.515.65.899 1.394 1.13 2.19.257.87.385 1.773.38 2.68.001.851-.114 1.7-.34 2.52a6.568 6.568 0 0 1-1 2.16 5.002 5.002 0 0 1-4.21 2.06c-.419 0-.837-.036-1.25-.11a5.39 5.39 0 0 1-1.2-.36A4.737 4.737 0 0 1 205 35a3.567 3.567 0 0 1-.81-.91v6.45h-2.89V22.83Zm10 6.47c0-.574-.078-1.146-.23-1.7a4.606 4.606 0 0 0-.67-1.46 3.475 3.475 0 0 0-1.12-1 3.06 3.06 0 0 0-1.55-.39A3.141 3.141 0 0 0 205 26a5.518 5.518 0 0 0-1 3.3c-.004.611.077 1.22.24 1.81.138.523.38 1.012.71 1.44a3.55 3.55 0 0 0 1.14 1 3.242 3.242 0 0 0 1.54.35 3.18 3.18 0 0 0 1.65-.4c.438-.25.817-.59 1.11-1 .299-.44.513-.931.63-1.45a7.38 7.38 0 0 0 .23-1.75h.05ZM228.67 35.75H226V34a3.38 3.38 0 0 1-1.67 1.61 5.668 5.668 0 0 1-2.33.49 6.17 6.17 0 0 1-2.66-.54 5.307 5.307 0 0 1-1.89-1.46 6.254 6.254 0 0 1-1.12-2.19 9.48 9.48 0 0 1-.37-2.71 8.67 8.67 0 0 1 .47-3 6.058 6.058 0 0 1 1.26-2.1 4.89 4.89 0 0 1 1.8-1.21 5.738 5.738 0 0 1 2.06-.39c.412 0 .824.037 1.23.11.413.073.815.194 1.2.36.38.166.736.381 1.06.64.32.255.594.562.81.91V17.9h2.85v17.85h-.03Zm-10-6.33c-.001.55.069 1.098.21 1.63.13.511.35.996.65 1.43.288.414.668.757 1.11 1a3.241 3.241 0 0 0 1.6.38 3.199 3.199 0 0 0 1.64-.4 3.398 3.398 0 0 0 1.13-1.05c.297-.447.517-.94.65-1.46.14-.542.211-1.1.21-1.66a5.227 5.227 0 0 0-1-3.35 3.175 3.175 0 0 0-2.61-1.2 3.23 3.23 0 0 0-1.69.41 3.478 3.478 0 0 0-1.12 1.07 4.494 4.494 0 0 0-.62 1.5 7.871 7.871 0 0 0-.11 1.7h-.05ZM242.6 32.88c-.018.258.03.516.14.75a.577.577 0 0 0 .54.23h.3c.135-.002.269-.019.4-.05v2l-.39.11-.49.08-.5.08h-.42a2.75 2.75 0 0 1-1.45-.35 1.731 1.731 0 0 1-.75-1.23 4.998 4.998 0 0 1-2.09 1.2 8.224 8.224 0 0 1-2.39.38 5.861 5.861 0 0 1-1.67-.24 4.394 4.394 0 0 1-1.41-.7 3.35 3.35 0 0 1-1-1.18 3.624 3.624 0 0 1-.36-1.66 3.84 3.84 0 0 1 .44-2 3.246 3.246 0 0 1 1.15-1.17 5.195 5.195 0 0 1 1.6-.61c.593-.127 1.19-.223 1.79-.29a14.77 14.77 0 0 1 1.47-.21 6.896 6.896 0 0 0 1.24-.21c.318-.077.611-.236.85-.46a1.286 1.286 0 0 0 .31-.94 1.458 1.458 0 0 0-.26-.9A1.759 1.759 0 0 0 239 25a2.807 2.807 0 0 0-.86-.25 6.941 6.941 0 0 0-.9-.06 3.58 3.58 0 0 0-2 .5 2 2 0 0 0-.87 1.55h-2.85c.021-.73.227-1.442.6-2.07.338-.54.797-.996 1.34-1.33a5.475 5.475 0 0 1 1.84-.7c.692-.134 1.395-.2 2.1-.2.632 0 1.262.067 1.88.2a5.337 5.337 0 0 1 1.66.65 3.6 3.6 0 0 1 1.19 1.16c.314.525.47 1.129.45 1.74v6.65l.02.04Zm-2.85-3.6a3.45 3.45 0 0 1-1.6.51c-.667.06-1.3.147-1.9.26a6.137 6.137 0 0 0-.87.21 2.64 2.64 0 0 0-.75.38c-.22.164-.395.38-.51.63a2.129 2.129 0 0 0-.19.94c-.011.29.085.575.27.8.182.215.407.388.66.51.269.128.555.216.85.26.277.05.558.076.84.08a4.63 4.63 0 0 0 1-.12 3.418 3.418 0 0 0 1-.43 2.73 2.73 0 0 0 .81-.76 1.93 1.93 0 0 0 .32-1.14v-2.14l.07.01ZM244.37 22.83h2.15V19h2.85v3.88h2.58V25h-2.58v6.9a7.064 7.064 0 0 0 0 .77c.016.194.074.381.17.55a.84.84 0 0 0 .41.34 2 2 0 0 0 .75.11h.6c.203-.01.404-.04.6-.09v2.2l-.93.1a8.403 8.403 0 0 1-.92 0 6.33 6.33 0 0 1-1.81-.21 2.421 2.421 0 0 1-1.08-.62 2.15 2.15 0 0 1-.52-1 7.791 7.791 0 0 1-.16-1.42V25h-2.15v-2.17h.04ZM256.22 30c-.002.491.069.98.21 1.45.131.448.348.866.64 1.23a3.08 3.08 0 0 0 1.08.84 3.543 3.543 0 0 0 1.55.31 3.431 3.431 0 0 0 2-.54c.541-.402.94-.966 1.14-1.61h2.7a5.352 5.352 0 0 1-2.1 3.26 5.715 5.715 0 0 1-1.74.85 7 7 0 0 1-2 .29 6.848 6.848 0 0 1-2.7-.5 5.577 5.577 0 0 1-2-1.4 5.947 5.947 0 0 1-1.21-2.18 8.754 8.754 0 0 1-.41-2.75 7.758 7.758 0 0 1 .44-2.61 6.67 6.67 0 0 1 1.25-2.17 5.863 5.863 0 0 1 4.56-2 5.79 5.79 0 0 1 2.74.64c.783.41 1.466.986 2 1.69a6.824 6.824 0 0 1 1.16 2.41c.243.916.308 1.87.19 2.81h-9.5V30Zm6.65-1.87a4.605 4.605 0 0 0-.29-1.3c-.148-.4-.368-.77-.65-1.09a3.22 3.22 0 0 0-1-.75 3 3 0 0 0-1.31-.29 3.431 3.431 0 0 0-1.36.26 3.108 3.108 0 0 0-1 .73 3.575 3.575 0 0 0-.7 1.09 3.798 3.798 0 0 0-.29 1.35h6.65-.05ZM270 31.6a2.154 2.154 0 0 0 .95 1.75c.607.35 1.3.524 2 .5.304-.002.608-.022.91-.06a3.943 3.943 0 0 0 1-.24c.286-.105.54-.28.74-.51a1.23 1.23 0 0 0 .26-.89 1.261 1.261 0 0 0-.4-.9 2.779 2.779 0 0 0-1-.56 9.315 9.315 0 0 0-1.34-.36l-1.5-.33a14.219 14.219 0 0 1-1.54-.42 4.937 4.937 0 0 1-1.33-.68 3.12 3.12 0 0 1-.94-1.09 3.472 3.472 0 0 1-.35-1.64 2.94 2.94 0 0 1 .51-1.76 3.913 3.913 0 0 1 1.3-1.15 5.66 5.66 0 0 1 1.75-.61 10.316 10.316 0 0 1 1.84-.17 8.418 8.418 0 0 1 1.91.21 5.19 5.19 0 0 1 1.65.69c.496.318.916.741 1.23 1.24.341.559.55 1.188.61 1.84h-3a1.783 1.783 0 0 0-.94-1.37 3.892 3.892 0 0 0-1.69-.35 6.093 6.093 0 0 0-.71 0 3.327 3.327 0 0 0-.78.19 1.642 1.642 0 0 0-.61.4 1 1 0 0 0-.25.69 1.093 1.093 0 0 0 .36.85c.294.245.634.428 1 .54.437.153.885.274 1.34.36l1.55.33a20.9 20.9 0 0 1 1.53.42c.479.157.931.386 1.34.68.41.277.751.643 1 1.07.255.494.379 1.045.36 1.6a3.48 3.48 0 0 1-.52 2 4.15 4.15 0 0 1-1.36 1.3 6.19 6.19 0 0 1-1.86.73 9.435 9.435 0 0 1-2 .23 8.823 8.823 0 0 1-2.26-.27 5.265 5.265 0 0 1-1.8-.84 4 4 0 0 1-1.2-1.4 4.445 4.445 0 0 1-.46-2h2.7v-.02Z"></path><path fill="#C72914" d="m21.94 38.74 18.12-12.08v-14.5H21.94v26.58Z"></path><path fill="#EF3340" d="M40.06 38.74 21.94 26.66v-14.5h18.12v26.58Z"></path><path fill="#3EB1C8" d="M31 9a20 20 0 1 0 0 40 20 20 0 0 0 0-40Zm0 35.1a15.1 15.1 0 1 1 0-30.2 15.1 15.1 0 0 1 0 30.2Z"></path><path fill="#FFC72C" d="M42.09 39.23A15.09 15.09 0 0 1 17 23.38l-4.2-2.64a20 20 0 0 0 33.49 21.14l-4.2-2.65Z"></path><defs><linearGradient id="horizontal_crossmark" x1="145" x2="145" y1="7.33" y2="56.82" gradientUnits="userSpaceOnUse"><stop stop-color="#fff"></stop><stop offset="1" stop-color="#c4c4c4"></stop></linearGradient></defs></svg></a></div><div class="core-related-do"></div><div class="info-panel"><div class="info-panel__left-content"><div class="info-panel__metrics info-panel__item">



        
        <div class="pub-metrics"><div class="issue-item__footer-info"><button tabindex="0" aria-haspopup="dialog" aria-expanded="false" aria-controls="metrics-tooltip-body-64p" title="Click to stay open" class="tooltip metrics-toggle"><span class="citation"><i aria-hidden="true" class="icon-quote"></i><span>1</span><span class="sr-only">citation</span></span><span class="metric"><i aria-hidden="true" class="icon-metric"></i><span>454</span></span><span class="sr-only">Downloads</span></button><div id="metrics-tooltip-body-64p" class="tooltip__body metrics-tooltip-body"><span class="arrow"></span><div class="left-bordered-title">Metrics</div><a href="#tab-citations" title="See Citations pane" class="tab-link"><div class="citation">Total Citations<span class="bold">1</span></div></a><a href="#tab-metrics-inner" title="See Bibliometrics pane" class="tab-link"><div class="metric">Total Downloads<span class="bold">454</span></div></a><div class="info">Last 12 Months<span class="bold">454</span></div><div class="info">Last 6 weeks<span class="bold">98</span></div></div></div></div>
</div></div><div class="info-panel__right-content"><div class="info-panel__article_tools info-panel__item">



        
        <button id="manageAlert__crtl" href="/action/addCitationAlert?doi=10.1145/3706599.3719940" data-toggle="modal" data-title="Get Citation Alerts" data-target="#manageAlert" aria-label="get citation alerts" title="Get Citation Alerts" class="article-actionbar__btn btn btn--icon simple-tooltip__block--b btn--slim"><i aria-hidden="true" class="icon-Icon_Alerts"></i><span class="visibility-hidden">Get Citation Alerts</span></button><div role="dialog" aria-labelledby="id-hatemile-navigation-6073290063892647-6" class="ux-modal-container"><div id="manageAlert" class="modal"><div class="modal__dialog"><div class="modal__dialog--success hidden"><div class="modal__header"><button type="button" data-dismiss="modal" aria-label="close popup" class="close"><i aria-hidden="true" class="icon-close_thin"></i></button><a id="id-hatemile-navigation-6073290063892647-7" name="id-hatemile-navigation-6073290063892647-7" data-headinganchorfor="id-hatemile-navigation-6073290063892647-6" class="heading-anchor"></a><h2 id="id-hatemile-navigation-6073290063892647-6">New Citation Alert added!</h2></div><div class="modal__body"><p>This alert has been successfully added and will be sent to:<span class="email"></span></p><p>You will be notified whenever a record that you have chosen has been cited.</p></div><div class="modal__footer"><p>To manage your alert preferences, click on the button below.</p><a href="/action/showPreferences?menuTab=Alerts" title="Manage my Alerts" id="id-hatemile-display-1019331959102511-5" class="btn blue big stretched manageAlert__btn"><span data-attributetitleof="id-hatemile-display-1019331959102511-5" class="force-read-before">Manage my Alerts</span></a></div></div><div class="modal__dialog--error hidden"><div class="modal__header"><button type="button" data-dismiss="modal" aria-label="close popup" class="close"><i aria-hidden="true" class="icon-close_thin"></i></button><a id="id-hatemile-navigation-6073290063892647-9" name="id-hatemile-navigation-6073290063892647-9" data-headinganchorfor="id-hatemile-navigation-6073290063892647-8" class="heading-anchor"></a><h2 id="id-hatemile-navigation-6073290063892647-8">New Citation Alert!</h2></div><div class="modal__body"><p>Please <a href="/action/showLogin?redirectUri=/doi/10.1145/3706599.3719940" title="Sign In" class="link">log in to your account</a></p></div></div></div></div></div>
</div><div class="info-panel__binder info-panel__item"><button data-title="Save to Binder" data-db-target-for="save-to-binder" data-link="/action/binderList?doi=10.1145/3706599.3719940" aria-label="save to binder" title="Save to Binder" class="article-actionbar__btn btn btn--icon simple-tooltip__block--b btn--slim saveToBinders"><i aria-hidden="true" class="icon-add-folder"></i></button></div><div class="info-panel__citations info-panel__item"><button data-title="Export Citation" data-target="#exportCitation" data-toggle="modal" aria-label="Export Citations" title="Export Citation" class="article-actionbar__btn btn btn--icon simple-tooltip__block--b btn--slim"><i aria-hidden="true" class="icon-quote"></i><input type="hidden" name="doiVal" value="10.1145/3706599.3719940"/></button></div><div class="info-panel__formats info-panel__item"><a href="https://dl.acm.org/doi/pdf/10.1145/3706599.3719940" class="btn btn--pdf red" aria-label="View PDF" title="View PDF"><i aria-hidden="true" class="icon-pdf-file"></i><span>PDF</span></a><a href="/doi/epdf/10.1145/3706599.3719940" class="btn btn--eReader blue" aria-label="View online with eReader" title="View online with eReader"><i aria-hidden="true" class="icon-eReader"></i><span>eReader</span></a></div></div></div></div></header><div data-core-nav="header" data-extent="frontmatter"><div class="core-nav-wrapper core-container" aria-label="Article navigation"><div><button aria-controls="article_sections_menu" aria-expanded="false" aria-label="Toggle section navigation menu"><i class="icon-burger" aria-hidden="true"></i><span>Contents</span></button><nav id="article_sections_menu" aria-label="Contents" data-core-nav="article"><header><div class="core-self-citation"><div property="isPartOf" typeof="Book"><a href="/doi/proceedings/10.1145/3706599" property="name">CHI EA '25: Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems</a></div><div class="core-publication-title" property="name">"A Great Start, But...": Evaluating LLM-Generated Mind Maps for Information Mapping in Video-Based Design</div><div property="pagination">Pages <span property="pageStart">1</span> - <span property="pageEnd">7</span></div></div><div class="content-navigation"><a href="/doi/10.1145/3706599.3719728" aria-label="Next chapter" aria-disabled="false" class="content-navigation__next"><div aria-hidden="true" class="content-navigation__hint"><div class="content-navigation__hint__content"><h6>NEXT CHAPTER</h6><div>"Ask Sir Oliver Ingham": LLM-based Social Simulations for History Education</div></div></div><span>Next</span><i aria-hidden="true" class="icon-Arrow-Stroke"></i></a></div></header><ul><li><a href="#summary-abstract">Abstract</a></li><li><a href="#sec-1">1 Introduction</a></li><li><a href="#sec-2">2 Methodology</a><ul><li><a href="#sec-2-1">2.1 Pre-Study Preparation</a></li><li><a href="#sec-2-2">2.2 Measurements of Performance in Information Mapping</a><ul><li><a href="#sec-2-2-1">2.2.1 Mind Map Evaluation Rubrics.</a></li><li><a href="#sec-2-2-2">2.2.2 Behaviour and Working Memory.</a></li></ul></li><li><a href="#sec-2-3">2.3 Experimental Procedure</a></li></ul></li><li><a href="#sec-3">3 Results &amp; Discussion</a><ul><li><a href="#sec-3-1">3.1 LLM-Generated Mind Maps Are Effective for Concept Linking but Lag in Hierarchical Organization (RQ1)</a></li><li><a href="#sec-3-2">3.2 LLM-Generated Mind Maps Save Time but Require More Visual Effort and Trust-Building (RQ2)</a></li><li><a href="#sec-3-3">3.3 Human-Generated Mind Maps Are More Usable, While LLMs Stand Out in Efficiency (RQ3)</a></li></ul></li><li><a href="#sec-4">4 Conclusion and Future Work</a></li><li><a href="#footnotes">Footnote</a></li><li><a href="#bibliography">References</a></li></ul><footer>



        
        <div class="logo">
    <img alt="ACM Digital Library" src="/specs/products/acm/releasedAssets/images/footer-logo1-45ae33115db81394d8bd25be65853b77.png" height="26" width="110" role="presentation" loading="eager">
</div>
</footer></nav></div><nav id="article_collateral_menu"><ul data-core-nav="collateral" class="collateral-pill"><li><a href="#core-collateral-info" data-id="article-nav-menubar-info" disabled="true" aria-disabled="true" aria-controls="core-collateral-info" title="Information & Contributors" tabindex="-1"><i aria-hidden="true" class="icon-Icon_Information"></i><span class="sr-only">Information &amp; Contributors</span></a></li><li><a href="#core-collateral-metrics" data-id="article-nav-menubar-metrics" disabled="true" aria-disabled="true" aria-controls="core-collateral-metrics" title="Bibliometrics & Citations" tabindex="-1"><i aria-hidden="true" class="icon-metric"></i><span class="sr-only">Bibliometrics &amp; Citations</span></a></li><li><a href="#core-collateral-fulltext-options" data-id="article-nav-menubar-metrics" disabled="true" aria-disabled="true" aria-controls="core-collateral-fulltext-options" title="View Options" tabindex="-1"><i aria-hidden="true" class="icon-eye"></i><span class="sr-only">View Options</span></a></li><li><a href="#core-collateral-references" data-id="article-nav-menubar-references" disabled="true" aria-disabled="true" aria-controls="core-collateral-references" title="References" tabindex="-1"><i aria-hidden="true" class="icon-Icon_Links-References"></i><span class="sr-only">References</span></a></li><li><a href="#core-collateral-figures" data-id="article-nav-menubar-figures" disabled="true" aria-disabled="true" aria-controls="core-collateral-figures" title="Figures" tabindex="-1"><i aria-hidden="true" class="icon-Icon_Images"></i><span class="sr-only">Figures</span></a></li><li><a href="#core-collateral-tables" data-id="article-nav-menubar-tables" disabled="true" aria-disabled="true" aria-controls="core-collateral-tables" title="Tables" tabindex="-1"><i aria-hidden="true" class="icon-table"></i><span class="sr-only">Tables</span></a></li><li><a href="#core-collateral-media" data-id="article-nav-menubar-media" disabled="true" aria-disabled="true" aria-controls="core-collateral-media" title="Media" tabindex="-1"><i aria-hidden="true" class="icon-play_circle_filled"></i><span class="sr-only">Media</span></a></li><li><a href="#core-collateral-share" data-id="article-nav-menubar-share" disabled="true" aria-disabled="true" aria-controls="core-collateral-share" title="Share" tabindex="-1"><i aria-hidden="true" class="icon-Icon_Share"></i><span class="sr-only">Share</span></a></li></ul></nav></div></div><div data-core-wrapper="content"><div id="abstracts" data-extent="frontmatter"><div class="core-container"><section id="summary-abstract" data-type="summary" property="abstract" typeof="Text" role="doc-abstract"><h2 property="name">Abstract</h2><div role="paragraph">Extracting concepts and understanding relationships from videos is essential in Video-Based Design (VBD), where videos serve as a primary medium for exploration but require significant effort in managing meta-information. Mind maps, with their ability to visually organize complex data, offer a promising approach for structuring and analysing video content. Recent advancements in Large Language Models (LLMs) provide new opportunities for meta-information processing and visual understanding in VBD, yet their application remains underexplored. This study recruited 28 VBD practitioners to investigate the use of prompt-tuned LLMs for generating mind maps from ethnographic videos. Comparing LLM-generated mind maps with those created by professional designers, we evaluated rated scores, design effectiveness, and user experience across two contexts. Findings reveal that LLMs effectively capture central concepts but struggle with hierarchical organization and contextual grounding. We discuss trust, customization, and workflow integration as key factors to guide future research on LLM-supported information mapping in VBD.</div></section></div></div><section id="bodymatter" data-extent="bodymatter" property="articleBody" typeof="Text"><div class="core-container"><div class="figure-wrap"><header><div class="label"><span class="core-label">Figure 1:</span></div></header><figure id="fig1" class="graphic"><img src="/cms/10.1145/3706599.3719940/asset/67fc1418-c663-4ec8-bded-421a392089ff/assets/images/medium/chiea25-455-fig1.jpg" height="227" width="500" aria-labelledby="fig1" data-viewer-src="/cms/10.1145/3706599.3719940/asset/f3c3b303-013e-492e-865e-934720a29b83/assets/images/large/chiea25-455-fig1.jpg" loading="lazy" /><figcaption><div role="paragraph">Both LLM- and human-generated mind maps were presented on a web-based platform (Fig. <a href="#fig1">1a</a>) for reviewing and editing design concepts during the lab study (Fig. <a href="#fig1">1b</a>).</div></figcaption></figure></div><section id="sec-1"><h2>1 Introduction</h2><div role="paragraph">In recent years, design processes have increasingly incorporated diverse tools and methods. The accessibility of video recording devices has established video as a widely used medium in design. The approach, referred to as Video-Based Design (VBD), is employed to use videos to identify design challenges, draw inspiration, and develop effective solutions [<a href="#Bib0024" role="doc-biblioref" data-xml-rid="Bib0024">24</a>, <a href="#Bib0026" role="doc-biblioref" data-xml-rid="Bib0026">26</a>, <a href="#Bib0030" role="doc-biblioref" data-xml-rid="Bib0030">30</a>, <a href="#Bib0031" role="doc-biblioref" data-xml-rid="Bib0031">31</a>]. By leveraging ethnographic videos [<a href="#Bib0020" role="doc-biblioref" data-xml-rid="Bib0020">20</a>]—recordings of human behaviours and interactions with products in situated environments—VBD provides designers with a rich, contextual understanding of user experiences. These videos serve as valuable tools to uncover latent issues and inspire innovative ideas [<a href="#Bib0031" role="doc-biblioref" data-xml-rid="Bib0031">31</a>]. However, ethnographic videos often contain fragmented elements, such as user interactions, environmental contexts, and personal narratives, which require substantial effort for designers to organize and distill into actionable insights. As Ylirisku and Buur emphasized, VBD demands that designers navigate large volumes of video content, extract the essence from the ethnographic footage, and systematically organize their findings into design decisions [<a href="#Bib0031" role="doc-biblioref" data-xml-rid="Bib0031">31</a>]. Traditionally, the organizing process in design relies on documentation techniques such as empathy mapping [<a href="#Bib0021" role="doc-biblioref" data-xml-rid="Bib0021">21</a>], customer journey mapping [<a href="#Bib0019" role="doc-biblioref" data-xml-rid="Bib0019">19</a>], and experience mapping [<a href="#Bib0022" role="doc-biblioref" data-xml-rid="Bib0022">22</a>], where designers use structured tables and visual frameworks to consolidate and interpret their insights cohesively.</div><div role="paragraph">Mind maps, on the other hand, act as a powerful alternative for managing complex information in this context. Their intuitive structure often enables users to integrate diverse data types and support for cognitive processes such as memory recall and association in tasks. As Kedaj et al. [<a href="#Bib0011" role="doc-biblioref" data-xml-rid="Bib0011">11</a>] stated, mind maps provide a visual representation of hierarchical relationships and associations which simplify and organize multifaceted data especially in professional tasks. The flexible connections between concepts in mind maps allow users to classify ideas based on semantic connections and enhance retention [<a href="#Bib0035" role="doc-biblioref" data-xml-rid="Bib0035">35</a>]. The use of mind maps for summarizing videos and enhancing professional tasks is increasingly prevalent. For instance, Siddarth et al. [<a href="#Bib0027" role="doc-biblioref" data-xml-rid="Bib0027">27</a>] developed a framework to generate hierarchical mind maps from video lectures which simplifies lecture content into organized structures to aid learning. Similarly, the pipeline introduced by Zhao and Yang [<a href="#Bib0036" role="doc-biblioref" data-xml-rid="Bib0036">36</a>] uses mind maps to organize users’ learnt knowledge with new concepts from tutorial videos to improve video-based learning. Additionally, Mammen et al. [<a href="#Bib0015" role="doc-biblioref" data-xml-rid="Bib0015">15</a>] demonstrated how mind maps can support qualitative data analysis by organizing video content using tools such as XMind into clear conceptual groupings for concepts.</div><div role="paragraph">The rise of Large Language Models (LLMs) such as GPT-4 [<a href="#Bib0016" role="doc-biblioref" data-xml-rid="Bib0016">16</a>], have demonstrated significant potential in organizing and synthesizing complex information [<a href="#Bib0005" role="doc-biblioref" data-xml-rid="Bib0005">5</a>, <a href="#Bib0037" role="doc-biblioref" data-xml-rid="Bib0037">37</a>]. Prior research highlights the capabilities of LLMs in addressing challenges related to data integration, knowledge fusion, and information processing. For instance, Yin et al. explored how LLMs’ semantic reasoning abilities, combined with prompt instruction tuning, can enhance users’ decision-making by distilling critical information from heterogeneous data sources [<a href="#Bib0029" role="doc-biblioref" data-xml-rid="Bib0029">29</a>]. Similarly, Remadi et al. revealed that LLMs possess the capability to extract entities and resolve ambiguities within unstructured datasets [<a href="#Bib0018" role="doc-biblioref" data-xml-rid="Bib0018">18</a>]. Additionally, Zhang et al. introduced Video-LLaMA [<a href="#Bib0034" role="doc-biblioref" data-xml-rid="Bib0034">34</a>], an LLM framework capable of understanding content in videos. Similarly, Video-ChatGPT proposed by Maaz et al. has demonstrated how integrating video-adapted visual encoders with LLMs can enhance temporal and spatial understanding in video content, further highlighting the potential of LLMs in structuring and processing video-based data [<a href="#Bib0014" role="doc-biblioref" data-xml-rid="Bib0014">14</a>]. Their framework leverages an LLM model and enables the automatic generation of text-based descriptions from videos. Despite these contributions, prior research has not yet examined the application of LLMs to improve video understanding and information processing within the context of VBD.</div><div role="paragraph">To explore the utilization of LLMs in design, we investigate their potential to streamline VBD by reducing low-level human effort in video understanding and fostering efficiency in collecting design concepts and their relationships to one another (design information mapping). Specifically, we focus on the application of LLM-generated mind maps—structured, visual tools that represent hierarchical information and relationships—to assist designers in synthesizing insights from ethnographic videos and organizing their design ideas on a unified platform. We address the following research questions:</div><div data-type="simple" role="list"><div id="list1" role="listitem"><div class="label">RQ1:</div><div class="content"><div role="paragraph">How are LLM-generated mind maps perceived compared to human-generated ones in information mapping of video-based design (VBD)?</div></div></div><div id="list2" role="listitem"><div class="label">RQ2:</div><div class="content"><div role="paragraph">In what ways do LLM-generated mind maps differ from human-generated mind maps in the effectiveness of practising in VBD workflows?</div></div></div><div id="list3" role="listitem"><div class="label">RQ3:</div><div class="content"><div role="paragraph">What impact do LLM-generated mind maps have on the designers’ acceptance and perceived usefulness compared to human-generated mind maps in aiding VBD?</div></div></div></div><div role="paragraph">To answer the questions, we conducted a controlled experimental study involving 28 designers from a university in scenario-based VBD exercises. We compared LLM-generated mind maps to human-generated ones to evaluate the performance of designers’ information understanding and organizing processes in VBD. As results, all participants recognized the potential of LLM-generated mind maps to enhance efficiency and provide a starting point for VBD. Many appreciated their ability to automate the labour-intensive process of initial information capture which promoted ideation for higher-levelled tasks. Our findings also show that while LLM-generated mind maps offer significant advantages in automating data capture from ethnographic videos and providing a foundational structure, they face challenges in usability, organization, and decision-making support compared to human-generated maps. These insights showcase the great potential of LLMs in upscaling design processes while drastically reducing human effort. Specifically, compared to human-generated mind maps, LLM-generated maps are: <b>1)</b> <i>More efficient in automating data capture but require more time for designers to edit and refinement.</i><b>2)</b> <i>Less effective in organizing hierarchical structures.</i><b>3)</b> <i>More demanding on cognitive load due to unstructured outputs, despite reducing initial manual effort.</i><b>4)</b> <i>More reliant on trust, workflow integration, and human oversight to support effective decision-making.</i></div></section><section id="sec-2"><h2>2 Methodology</h2><div role="paragraph">We conducted a within-subject experimental study over three weeks to examine how LLM-generated mind maps compare to human-generated mind maps in supporting information mapping of VBD. The independent variable was the type of mind map, which included two conditions: human-generated and LLM-generated. We developed a workflow using GPT-4o [<a href="#Bib0016" role="doc-biblioref" data-xml-rid="Bib0016">16</a>] to generate mind maps from videos and integrated them into a web-based tool. The tool includes a video player and an interface that allows users to view and modify the mind maps. This section details participants, experimental procedure, and measurements of performance in information mapping of VBD.</div><section id="sec-2-1"><h3>2.1 Pre-Study Preparation</h3><div class="figure-wrap"><header><div class="label"><span class="core-label">Figure 2:</span></div></header><figure id="fig2" class="graphic"><img src="/cms/10.1145/3706599.3719940/asset/d85d297b-f455-4543-9f0b-f2ddd1288f9d/assets/images/medium/chiea25-455-fig2.jpg" height="270" width="500" aria-labelledby="fig2" data-viewer-src="/cms/10.1145/3706599.3719940/asset/4e51b6ad-b8d8-47a0-a6fa-d05e37d67313/assets/images/large/chiea25-455-fig2.jpg" loading="lazy" /><figcaption><div role="paragraph">Screenshots for the two contexts used in the study: Fig. <a href="#fig2">2a</a> shows a screenshot from a video about an autonomous taxi navigating a busy urban intersection with traffic signals, pedestrians, and other vehicles. Fig. <a href="#fig2">2b</a> shows a screenshot from a video showing a visually impaired user demonstrating accessibility tools on her phone, such as voiceover and screen reader functionalities, to navigate, type, and make a post on social media.</div></figcaption></figure></div><div role="paragraph">We recruited 28 design students (9 females and 19 males) from our university. The participants had an average age of 25.8 years (SD = 1.9) and an average of 5.1 years of design experience (SD = 2.6). We asked participants to self-evaluate their experience with VBD (VBD-XP) and their perceived reliability of LLMs in daily tasks. Regarding LLM reliability, participants rated it as "high (daily)" (n=9), "moderate (weekly)" (n=9), and "rare (occasionally)" (n=10). Results indicate that 53.6% of participants had high or moderate confidence in their VBD experience and 64.3% relied on LLMs in their daily or weekly practices.</div><div role="paragraph">For design contexts, we selected two video scenarios each lasting 2 minutes and 20 seconds. These scenarios were carefully chosen based on professional designers’ input to represent two primary categories of video content commonly encountered by designers: 1) repetitive and informative point-of-view recordings, and 2) user-product interactions. As indicated in Fig. <a href="#fig2">2</a>, the chosen contexts were an autonomous car navigating an urban environment (Fig. <a href="#fig2">2a</a>) and a demonstration of a mobile phone accessibility features showed by a visually impaired user (fig. <a href="#fig2">2b</a>). Both videos were also standardized in bit rate to ensure consistency and fairness in participant evaluations. Based on the two selected videos, four mind maps were generated: one LLM-generated and one human-generated mind map for each video.</div><div role="paragraph">To create the LLM-generated mind maps, we utilized</div><div role="paragraph"><span data-style="monospace">blip2-opt-6.7b</span><a href="#fn1" role="doc-noteref"><sup>1</sup></a>, a state-of-the-art Vision-Language Model (VLM), to transcribe the video content into textual descriptions. These descriptions were then processed using GPT-4 [<a href="#Bib0016" role="doc-biblioref" data-xml-rid="Bib0016">16</a>] with prompt fine-tuning to convert them into mind maps. In the fine-tuning process, the video descriptions along with their corresponding scenario topics, were incorporated into the prompts (see Supplementary Text 1 in Appendix). We used prompts to instructed LLM to organize the video descriptions into a structured JSON format, which was then visualized as a mind map on the study platform. Additionally, for the human-generated mind maps, an independent designer was tasked with creating two mind maps for the two videos. The designer spent 10 minutes analysing each video to grasp its fundamental concepts. They then hand-drew a radial mind map on paper, which is a widely-used method in mind mapping to organize thoughts around a central theme [<a href="#Bib0006" role="doc-biblioref" data-xml-rid="Bib0006">6</a>]. The designer spent an additional 20 minutes to digitally transfer the mind map into a JSON file which is similar to the LLM-generated ones. To keep pairwise comparison in the study, both the human- and LLM-generated mind maps were designed to maintain a similar number of topics, keywords and links between them as closely as possible.</div><div role="paragraph">We then developed a web-based platform (Fig. <a href="#fig1">1a</a>) consisting of two panels: a video player and a mind map editing panel. The video player on the left allowed participants to review and navigate the video content using controls such as play and pause. On the right side, the mind map editing panel displayed the mind maps visualized from JSON files. This panel enabled participants to actively edit the mind maps by moving nodes, modifying text, and adding or deleting links based on their understanding and interpretation of the video content and mind maps. Additionally, We included a countdown timer in the upper left corner to remind participants of the remaining time for their tasks.</div></section><section id="sec-2-2"><h3>2.2 Measurements of Performance in Information Mapping</h3><section id="sec-2-2-1"><h4>2.2.1 Mind Map Evaluation Rubrics.</h4><div role="paragraph">Due to time constraints in creating mind maps from scratch, our study used pre-created mind maps generated in advance using both LLM and human methods. Participants were asked to evaluate the mind maps from a designer’s perspective and rate them using a holistic scoring approach based on the established Mind Map Scoring Rubric (MMSR) [<a href="#Bib0009" role="doc-biblioref" data-xml-rid="Bib0009">9</a>]. The MMSR holistic scoring approach was chosen not only for its alignment with evaluators’ perceptions of critical factors like accuracy and proficiency [<a href="#Bib0032" role="doc-biblioref" data-xml-rid="Bib0032">32</a>] but also because it demonstrates higher inter-rater reliability for consistency compared to other qualitative rubrics [<a href="#Bib0025" role="doc-biblioref" data-xml-rid="Bib0025">25</a>]. In our study, we measured four key variables based on MMSR: 1) Identification of triggers (recognizing key concepts in the problem), 2) Development of concept links (exploring and expanding knowledge through valid connections), 3) Development of hierarchies (organizing concepts logically with core ideas at the center and specifics on the periphery), and 4) Identification of cross-links and relationship links (showing meaningful connections between different concepts and within a concept).</div></section><section id="sec-2-2-2"><h4>2.2.2 Behaviour and Working Memory.</h4><div role="paragraph">We adopted the questionnaire of Unified Theory of Acceptance and Use of Technology 2 (UTAUT2) [<a href="#Bib0023" role="doc-biblioref" data-xml-rid="Bib0023">23</a>] to understand participant behaviour in mapping information. UTAUT2 measures participants’ willingness to integrate and use the mind maps on the study platform in their design workflows [<a href="#Bib0023" role="doc-biblioref" data-xml-rid="Bib0023">23</a>]. The questionnaire assessed responses across eight categories: Performance Expectancy (perceived benefits), Effort Expectancy (ease of use), Social Influence (impact of others’ opinions), Facilitating Conditions (availability of resources and support), behavioural Intention (intent to use), Hedonic Motivation (enjoyment), Price Value (cost-effectiveness), and Habit (routine use). In addition, as working memory is critical for information processing and decision-making in advanced tasks [<a href="#Bib0017" role="doc-biblioref" data-xml-rid="Bib0017">17</a>], we also assessed participants’ cognitive load using NASA-TLX questionnaire [<a href="#Bib0008" role="doc-biblioref" data-xml-rid="Bib0008">8</a>]. As an objective-based measurement of cognitive load [<a href="#Bib0001" role="doc-biblioref" data-xml-rid="Bib0001">1</a>], eye-tracking glasses (see Fig. <a href="#fig1">1b</a>) were also used to capture participants’ eye movements, including saccades (rapid movements between focus points), fixations (sustained focus on a single point), pupil sizes (diameter of pupils), and blinks (rapid eyelid closures).</div></section></section><section id="sec-2-3"><h3>2.3 Experimental Procedure</h3><div class="figure-wrap"><header><div class="label"><span class="core-label">Table 1:</span></div></header><figure id="tab1" class="table"><div class="table-wrap"><table><thead><tr><th style="border-bottom: 2pt solid #000000">Process</th><th style="border-bottom: 2pt solid #000000">Task</th><th style="border-bottom: 2pt solid #000000">Measurements</th></tr></thead><tbody><tr data-xml-align="center"><td>Preparation</td><td>Signing consent forms</td><td>validity check</td></tr><tr data-xml-align="center"><td> </td><td>Providing demographic information</td><td>validity check</td></tr><tr data-xml-align="center"><td style="border-bottom: 2pt solid #000000"> </td><td style="border-bottom: 2pt solid #000000">Having tutorials on study steps and tool usage</td><td style="border-bottom: 2pt solid #000000">Inquiry and validity check</td></tr><tr data-xml-align="center"><td>Main Session</td><td>Watching video A</td><td>Eye-tracking</td></tr><tr data-xml-align="center"><td> </td><td>Reviewing mind map A</td><td>Eye-tracking</td></tr><tr data-xml-align="center"><td style="border-bottom: 2pt solid #000000"> </td><td style="border-bottom: 2pt solid #000000">Evaluating mind map A</td><td style="border-bottom: 2pt solid #000000">MMSR [<a href="#Bib0009" role="doc-biblioref" data-xml-rid="Bib0009">9</a>]</td></tr><tr data-xml-align="center"><td> </td><td>Modifying mind map A</td><td>Eye-tracking and Interaction logs</td></tr><tr data-xml-align="center"><td> </td><td>Repeating tasks above with video B and mind map B</td><td>Measurements in task A</td></tr><tr data-xml-align="center"><td>Post-Session</td><td>Completing Post-Task Surveys</td><td>NASA-TLX [<a href="#Bib0008" role="doc-biblioref" data-xml-rid="Bib0008">8</a>] and UTAUT2 [<a href="#Bib0023" role="doc-biblioref" data-xml-rid="Bib0023">23</a>]</td></tr><tr data-xml-align="center"><td style="border-bottom: 2pt solid #000000"> </td><td style="border-bottom: 2pt solid #000000">Having an interview (10 min)</td><td style="border-bottom: 2pt solid #000000">Qualitative feedback on mind maps’ reasoning</td></tr></tbody></table></div><figcaption><div role="paragraph">Overview of the experimental procedure with tasks performed by participants, and the measurements collected from preparation, main session and post-session of the study.</div></figcaption></figure></div><div role="paragraph">As showed in Table <a href="#tab1">1</a>, the experiment consisted of three phases: preparation, the main session, and post-session surveys and interview. Participants began by signing consent forms and provided demographic information. A brief tutorial introduced participants to the study’s objectives, procedures, and the equipments used for the tasks. Participants were then assigned two tasks (A and B), which involved reviewing the two videos and editing the corresponding LLM- or human-generated mind maps. The order was predetermined using a randomized counterbalanced scheme. In the main session, participants began with Task A, where they first watched the assigned video (either context of autonomous car navigation or mobile phone accessibility features in Fig. <a href="#fig2">2</a>). They then reviewed the corresponding mind map A (either human- or LLM-generated) for 3 minutes. Participants then instructed to use the MMSR rubrics [<a href="#Bib0009" role="doc-biblioref" data-xml-rid="Bib0009">9</a>] to evaluate mind map A on the four categories mentioned in Section <a href="#sec-2-2-1">2.2.1</a> on a scale from 1 to 100. Afterward, participants were given 10 minutes to modify mind map A using the web-based platform (see Section <a href="#sec-2-1">2.1</a>). This process was repeated for Task B, where participants watched the second video (video B), reviewed, evaluated and edited the corresponding mind map B. Each task lasted approximately 20 minutes. By the end of the session, each participant was exposed to both versions of the mind maps (human- and LLM-generated) across the two video contexts. In the post-session, participants first completed the NASA-TLX questionnaire, followed by UTAUT2, and then interviewed about their experience in the study.</div></section></section><section id="sec-3"><h2>3 Results &amp; Discussion</h2><div role="paragraph">We present the results of our experiment, which investigated the performance of information mapping using two methods across three dimensions: rating in effectiveness (RQ1), effectiveness in practice (RQ2), and use experience (RQ3). Statistical significance was determined using paired-samples t-tests and Wilcoxon signed-rank tests. Post-session interviews were analysed using thematic analysis [<a href="#Bib0002" role="doc-biblioref" data-xml-rid="Bib0002">2</a>] in ATLAS.ti to complement the quantitative results.</div><section id="sec-3-1"><h3>3.1 LLM-Generated Mind Maps Are Effective for Concept Linking but Lag in Hierarchical Organization (RQ1)</h3><div role="paragraph">We first analysed how participants evaluated LLM- and human-generated mind maps using the four categories from the MMSR described in Section <a href="#sec-2-2-1">2.2.1</a>. No significant differences were found between LLM- and human-generated mind maps in three of the four categories: <b>identification of triggers</b> (Wilcoxon, Z = -0.054, p = 0.957), <b>development of concept links</b> (paired-samples t, t(27) = 0.478, p = 0.637), and <b>identification of cross-links and relationship links</b> (Wilcoxon, Z = -1.058, p = 0.290). It indicates that LLM-generated mind maps effectively identify key concepts from VBD videos, expand relevant knowledge, and establish meaningful connections. In this case, LLMs can generate mind maps with comparable information extraction and linkage to those created by professional designers, while potentially requiring less effort and reducing fatigue. However, a significant difference was observed in the category of the <b>development of hierarchies</b>, which measures the ability to logically organize and categorize concepts in VBD videos’ information mapping. Human-generated mind maps scored significantly higher than LLM-generated ones (paired-samples t, t(27) = 2.456, p = 0.021). On average, human-generated mind maps scored 11.35% higher in this category (LLM-generated: 50.79 ± 23.87 points, human-generated: 62.14 ± 23.99 points). While LLM-generated mind maps perform well in capturing and linking concepts, they fall short in logically structuring information with core and relevant ideas. From our interviews, a similar pattern was observed. Participants (P4, P5, P11, P16, P18-21) noted that while LLM-generated mind maps enhance efficiency by providing a solid starting point with some connections between topics, human-generated information mapping still advantages in organizing clear categorization and deeper analysis on information.</div></section><section id="sec-3-2"><h3>3.2 LLM-Generated Mind Maps Save Time but Require More Visual Effort and Trust-Building (RQ2)</h3><div role="paragraph">A Wilcoxon signed-rank test revealed that the time taken to analyse LLM- and human-generated mind maps in the study had no statistical significance (Z = -1.548, p =.122). However, a closer analysis showed that participants spent an additional 1.92 minutes on average editing LLM-generated mind maps compared to human-generated ones across the two design contexts (paired-samples t, t(28) = -2.278, p &lt;.015; LLM-generated: 7.39 ± 3.58 min, human-generated: 5.47 ± 2.95 min). Furthermore, as cognitive load plays a significant role in influencing the effectiveness of information processing during design tasks [<a href="#Bib0003" role="doc-biblioref" data-xml-rid="Bib0003">3</a>, <a href="#Bib0004" role="doc-biblioref" data-xml-rid="Bib0004">4</a>], we employed NASA-TLX questionnaire to measure participants’ working memory. A paired-samples t-test revealed no significant difference in self-reported cognitive load between the two conditions (t(27) = -1.291, p =.208). This indicates that participants perceived similar cognitive demands for both LLM- and human-generated mind maps. In addition to self-reported cognitive workload, we also used eye-tracking glasses to record participants’ eye movements while reviewing and editing the mind maps. Paired-samples t-tests revealed that no significant differences found in eye fixation duration (t(27) = -.045, p =.964), blink duration (t(27) =.999, p =.327), or changes in pupil diameter (t(27) = -.870, p =.196) between the two conditions. However, a significant difference was observed in eye saccade duration, with participants spending 3.92% more time sweeping through LLM-generated mind maps compared to human-generated ones (Wilcoxon, Z = -2.482, p =.013; LLM-generated: M = 60.96, SD = 21.76 ms; human-generated: M = 58.57, SD = 15.84 ms). Additionally, participants scanned the LLM-generated maps faster than the human-generated ones. A paired-samples t-test revealed that participants’ eye movement speed was 4.46% higher in the LLM-generated condition compared to the human-generated condition (t(27) = 2.113, p =.004; LLM-generated: M = 3674.97, SD = 561.03 px/s; human-generated: M = 3511.02, SD = 641.91 px/s). Participants were likely moving their gaze more quickly to navigate the elements in the LLM-generated maps. Together, these findings suggest that while the overall cognitive load was comparable across conditions, LLM-generated mind maps required more visual effort and faster scanning to interpret their contents effectively.</div><div role="paragraph">The later interviews confirmed the efficiency of both mind map types in formalizing information for VBD. P6 noted the time-saving aspect of LLM-generated mind maps: “[P6] One click and you get a mind map; it’s valuable but needs better structure.” Conversely, P25 appreciated human-generated mind maps for reducing the effort of video analysis: “[P25] It saves time and avoids burnout.” Some participants (P1, P16, and P18) highlighted the redundant keywords in LLM-generated mind maps but acknowledged the flexibility to ignore irrelevant elements. However, our further qualitative results revealed that the lack of trust from participants in LLM-generated mind maps significantly influenced their editing time. This resulted in having more time for additional visual and logical verification in the editing process. P25 stated that they did not "trust" the LLM-generated outputs, while P17 emphasized the need for "further adjustments" to make the LLM-generated mind maps more usable. As P5 mentioned, “[P5] You need to verify what’s in the video and the (LLM-generated) mind map. You shouldn’t just blindly accept it.” Similarly, P9 emphasized that information mapping “should involve human input” to ensure the accuracy and reliability of the LLM-supported tool for VBD tasks.</div></section><section id="sec-3-3"><h3>3.3 Human-Generated Mind Maps Are More Usable, While LLMs Stand Out in Efficiency (RQ3)</h3><div role="paragraph">We then analysed self-rated scores from the UTAUT2 framework (see Section <a href="#sec-2-2-2">2.2.2</a>) to measure participants’ acceptance and perceived usefulness of the two types of mind maps. In the categories of <b>social influence</b> (Wilcoxon, Z = -.460, p =.646), <b>facilitating conditions</b> (Wilcoxon, Z = -.577, p =.564), <b>hedonic motivation</b> (Wilcoxon, Z = -.408, p =.683), <b>price value</b> (Wilcoxon, Z = -.277, p =.782), and <b>habit</b> (Wilcoxon, Z = -1.112, p =.265), no significant differences were observed between LLM- and human-generated mind maps. However, paired-samples t-tests revealed significant differences between the two types of mind maps in the categories of <b>performance expectancy (PE)</b> (t(27) = 2.545, p =.017), <b>effort expectancy (EE)</b> (t(27) = 2.100, p =.045), and <b>behavioural intention (BI)</b> (t(27) = 2.464, p =.020). Participants reported higher scores for human-generated mind maps compared to LLM-generated ones across these three categories: PE (human-generated: 4.13 ± 0.53; LLM-generated: 3.88 ± 0.70), EE (human-generated: 3.88 ± 0.78; LLM-generated: 3.64 ± 0.72), and BI (human-generated: 3.87 ± 0.15; LLM-generated: 3.59 ± 0.16). From our interviews, participants frequently (n=11) noted that LLM-generated mind maps lacked the intuitive structure and customization designers expect. Participants also observed that LLM-generated mind maps lacked the contextual understanding of design concepts typically found in human-generated maps. On the other hand, some participants (n=6) acknowledged the LLM’s ability to capture extensive details and make gathering and organizing data "way more efficient" (P2). Additionally, we also found that ease of use and familiarity with the mind-mapping tool significantly influenced participants’ perceptions of LLM-generated maps. P11 noted some initial difficulties in interpreting the LLM-generated mind maps, saying, “[P11] I couldn’t get insights from the mind map because I didn’t know how to read the mind map (the connections between concepts).” This highlights the importance of intuitive design that facilitates quick comprehension and efficient navigation. However, training and continued use can mitigate these challenges: “[P13] It was more difficult at first, and then I found the value of it; it became easier for me.” Additionally, some participants (P23, P25-26) claimed that the flexibility in mind map editing and customization in concepts emerged as another critical factor for usability. The ability to modify and tailor mind maps not only enhances their relevance but also keeps designers actively engaged with the content and foster closer alignment with design goals.</div></section></section><section id="sec-4"><h2>4 Conclusion and Future Work</h2><div role="paragraph">This LBW provides early insights into the use of LLM-generated mind maps in supporting information mapping in VBD. Through a controlled experimental study with 28 designers, we evaluated the performance of LLM-generated mind maps compared to human-generated ones across self-rated scores, effectiveness and user acceptance. LLM-generated mind maps demonstrated advantages in effective collecting data captured from videos in VBD, consistent with previous studies that highlight the effectiveness of LLMs in processing complex information [<a href="#Bib0010" role="doc-biblioref" data-xml-rid="Bib0010">10</a>, <a href="#Bib0028" role="doc-biblioref" data-xml-rid="Bib0028">28</a>]. However, compared to the human-generated baseline, LLM-generated mind maps were often criticized for their lack of coherent hierarchies and contextual understanding, and usually required additional manual refinement. Factors such as trust, transparency, and the ability to customize were also identified as critical to the acceptance of LLM-generated mind maps in VBD tasks.</div><div role="paragraph">To enhance the utility of LLM-generated mind maps in VBD’s information mapping workflows, we will focus on improving structural and contextual alignment with design processes. We will start from refining prompt templates [<a href="#Bib0033" role="doc-biblioref" data-xml-rid="Bib0033">33</a>] or developing better technical solutions for distilling LLM prompts [<a href="#Bib0012" role="doc-biblioref" data-xml-rid="Bib0012">12</a>] to enhance the hierarchical organization of design concepts and foster further customization and usability. Additionally, in our future studies, transparency should also be prioritized to build trust and improve usability. Implementing mechanisms such as detailed model reporting, clear explanations of LLMs’ limitations, and visual feedback on reliability can help users better understand the capabilities and constraints of AI-generated outputs [<a href="#Bib0013" role="doc-biblioref" data-xml-rid="Bib0013">13</a>]. Finally, as highlighted in previous research [<a href="#Bib0007" role="doc-biblioref" data-xml-rid="Bib0007">7</a>], presenting LLMs’ uncertainty using less precise but interpretable language could further enhance both the usability and trustworthiness of LLM-generated contents in future information processing tasks.</div></section><div class="figure-wrap"><figure class="boxed-text"><div role="paragraph"><span data-style="monospace">Output a JSON as plain text to describe the scenario. The JSON should contains nodes whose “label” are related keywords from the topic and edges with “label” as relationships. Include unique ID, position, size, shape for nodes; source, target for edges; and styles for both, with edge length reflecting semantic relevance. Do not put the same IDs for edges. Depend on the contents, generate more than 20 but not less than 30 nodes and edges, and generate 1 to 3 levels of branches as subtopics. Use different node and edge colors and edge lengths to represent relationships. Avoid overlapping. Focus on objective interactions. This is an example: “ “nodes”: [ “id”: “Node1”, “x”: 50, “y”: 50, “size”: [60, 60], “shape”: “circle”, “label”: “Apple”,“id”: “Node2”, “x”: 200, “y”: 50, “size”: [60, 60], “shape”: “circle”, “label”: “iOS”, “id”: “Node3”, “x”: 350, “y”: 50, “size”: [60, 60], “shape”: “circle”, “label”: “App Store”,...]”. Use the example as a template for generation but follow the rules above. This is the scenario: “...”. Here is the transcript: “...”.</span></div></figure></div><div role="paragraph"><b>Supplementary Text 1: Instructional text displayed.</b></div></div></section><section id="backmatter" data-extent="backmatter"><div class="core-container"><section id="footnotes"><h2>Footnote</h2><div role="doc-footnote" data-has="label"><div class="label"><sup>1</sup></div><div id="fn1" role="paragraph"><a href="https://huggingface.co/Salesforce/blip2-opt-6.7b" target="_blank">https://huggingface.co/Salesforce/blip2-opt-6.7b</a> (last accessed: 2025/03/04 10:57:04).</div></div></section><section id="bibliography" role="doc-bibliography"><h2>References</h2><div role="list"><div role="listitem" data-has="label"><div class="label">[1]</div><div id="Bib0001" class="citations"><div class="citation"><div class="citation-content">Ulf Ahlstrom and Ferne J Friedman-Berg. 2006. Using eye movement activity as a correlate of cognitive workload. <em>International journal of industrial ergonomics</em> 36, 7 (2006), 623–636.</div><div class="external-links"><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Using+eye+movement+activity+as+a+correlate+of+cognitive+workload&amp;author=Ulf+Ahlstrom&amp;author=Ferne%C2%A0J+Friedman-Berg&amp;publication_year=2006&amp;pages=623-636">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[2]</div><div id="Bib0002" class="citations"><div class="citation"><div class="citation-content">Julie Ayre and Kirsten J McCaffery. 2022. Research Note: Thematic analysis in qualitative research. <em>J Physiother</em> (2022).</div><div class="external-links"><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Research+Note%3A+Thematic+analysis+in+qualitative+research.&amp;author=Julie+Ayre&amp;author=Kirsten%C2%A0J+McCaffery&amp;publication_year=2022">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[3]</div><div id="Bib0003" class="citations"><div class="citation"><div class="citation-content">Linden J Ball and Thomas C Ormerod. 2000. Putting ethnography to work: the case for a cognitive ethnography of design. <em>International Journal of Human-Computer Studies</em> 53, 1 (2000), 147–168.</div><div class="external-links"><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Putting+ethnography+to+work%3A+the+case+for+a+cognitive+ethnography+of+design&amp;author=Linden%C2%A0J+Ball&amp;author=Thomas%C2%A0C+Ormerod&amp;publication_year=2000&amp;pages=147-168">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[4]</div><div id="Bib0004" class="citations"><div class="citation"><div class="citation-content">Lyn Bartram, Michael Correll, and Melanie Tory. 2021. Untidy data: The unreasonable effectiveness of tables. <em>IEEE Transactions on Visualization and Computer Graphics</em> 28, 1 (2021), 686–696.</div><div class="external-links"><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Untidy+data%3A+The+unreasonable+effectiveness+of+tables&amp;author=Lyn+Bartram&amp;author=Michael+Correll&amp;author=Melanie+Tory&amp;publication_year=2021&amp;pages=686-696">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[5]</div><div id="Bib0005" class="citations"><div class="citation"><div class="citation-content">G Bharathi Mohan, R Prasanna Kumar, P Vishal Krishh, A Keerthinathan, G Lavanya, Meka Kavya Uma Meghana, Sheba Sulthana, and Srinath Doss. 2024. An analysis of large language models: their impact and potential applications. <em>Knowledge and Information Systems</em> (2024), 1–24.</div><div class="external-links"><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=An+analysis+of+large+language+models%3A+their+impact+and+potential+applications&amp;author=G+Bharathi%C2%A0Mohan&amp;author=R+Prasanna%C2%A0Kumar&amp;author=P+Vishal%C2%A0Krishh&amp;author=A+Keerthinathan&amp;author=G+Lavanya&amp;author=Meka+Kavya%C2%A0Uma+Meghana&amp;author=Sheba+Sulthana&amp;author=Srinath+Doss&amp;publication_year=2024&amp;pages=1-24">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[6]</div><div id="Bib0006" class="citations"><div class="citation"><div class="citation-content">Tony Buzan and Barry Buzan. 2006. <em>The mind map book</em>. Pearson Education.</div><div class="external-links"><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=The+mind+map+book&amp;author=Tony+Buzan&amp;author=Barry+Buzan&amp;publication_year=2006">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[7]</div><div id="Bib0007" class="citations"><div class="citation"><div class="citation-content">Akseli Graf and Rick E Bernardi. 2023. ChatGPT in research: balancing ethics, transparency and advancement. <em>Neuroscience</em> 515 (2023), 71–73.</div><div class="external-links"><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=ChatGPT+in+research%3A+balancing+ethics%2C+transparency+and+advancement&amp;author=Akseli+Graf&amp;author=Rick%C2%A0E+Bernardi&amp;publication_year=2023&amp;pages=71-73">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[8]</div><div id="Bib0008" class="citations"><div class="citation"><div class="citation-content">Sandra G Hart. 1986. NASA task load index (TLX). (1986).</div><div class="external-links"><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=NASA+task+load+index+%28TLX%29&amp;author=Sandra%C2%A0G+Hart&amp;publication_year=1986">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[9]</div><div id="Bib0009" class="citations"><div class="citation"><div class="citation-content">Cheng Hua and Stefanie A Wind. 2019. Exploring the psychometric properties of the mind-map scoring rubric. <em>Behaviormetrika</em> 46, 1 (2019), 73–99.</div><div class="external-links"><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Exploring+the+psychometric+properties+of+the+mind-map+scoring+rubric&amp;author=Cheng+Hua&amp;author=Stefanie%C2%A0A+Wind&amp;publication_year=2019&amp;pages=73-99">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[10]</div><div id="Bib0010" class="citations"><div class="citation"><div class="citation-content">Bin Huang, Xin Wang, Hong Chen, Zihan Song, and Wenwu Zhu. 2024. Vtimellm: Empower llm to grasp video moments. In <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>. 14271–14280.</div><div class="external-links"><div class="core-xlink-crossref"><a href="https://doi.org/10.1109/CVPR52733.2024.01353">Crossref</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Vtimellm%3A+Empower+llm+to+grasp+video+moments&amp;author=Bin+Huang&amp;author=Xin+Wang&amp;author=Hong+Chen&amp;author=Zihan+Song&amp;author=Wenwu+Zhu&amp;publication_year=2024&amp;pages=14271-14280&amp;doi=10.1109%2FCVPR52733.2024.01353">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[11]</div><div id="Bib0011" class="citations"><div class="citation"><div class="citation-content">Petr Kedaj, Josef Pavlíček, Petr Hanzlík, et al. 2014. Effective mind maps in e-learning. <em>Acta Informatica Pragensia</em> 3, 3 (2014), 239–250.</div><div class="external-links"><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Effective+mind+maps+in+e-learning&amp;author=Petr+Kedaj&amp;author=Josef+Pavl%C3%AD%C4%8Dek&amp;author=Petr+Hanzl%C3%ADk&amp;publication_year=2014&amp;pages=239-250">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[12]</div><div id="Bib0012" class="citations"><div class="citation"><div class="citation-content">Lei Li, Yongfeng Zhang, and Li Chen. 2023. Prompt distillation for efficient llm-based recommendation. In <em>Proceedings of the 32nd ACM International Conference on Information and Knowledge Management</em>. 1348–1357.</div><div class="external-links"><div class="core-xlink-digital-library"><a href="/doi/10.1145/3583780.3615017">Digital Library</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Prompt+distillation+for+efficient+llm-based+recommendation&amp;author=Lei+Li&amp;author=Yongfeng+Zhang&amp;author=Li+Chen&amp;publication_year=2023&amp;pages=1348-1357&amp;doi=10.1145%2F3583780.3615017">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[13]</div><div id="Bib0013" class="citations"><div class="citation"><div class="citation-content">Q Vera Liao and Jennifer Wortman Vaughan. 2023. Ai transparency in the age of llms: A human-centered research roadmap. <em>arXiv preprint arXiv:<a href="https://arXiv.org/abs/2306.01941" target="_blank">https://arXiv.org/abs/2306.01941</a></em> (2023), 5368–5393.</div><div class="external-links"><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Ai+transparency+in+the+age+of+llms%3A+A+human-centered+research+roadmap&amp;author=Q%C2%A0Vera+Liao&amp;author=Jennifer%C2%A0Wortman+Vaughan&amp;publication_year=2023&amp;pages=5368-5393">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[14]</div><div id="Bib0014" class="citations"><div class="citation"><div class="citation-content">Muhammad Maaz, Hanoona Rasheed, Salman Khan, and Fahad Shahbaz Khan. 2023. Video-chatgpt: Towards detailed video understanding via large vision and language models. <em>arXiv preprint arXiv:<a href="https://arXiv.org/abs/2306.05424" target="_blank">https://arXiv.org/abs/2306.05424</a></em> (2023).</div><div class="external-links"><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Video-chatgpt%3A+Towards+detailed+video+understanding+via+large+vision+and+language+models&amp;author=Muhammad+Maaz&amp;author=Hanoona+Rasheed&amp;author=Salman+Khan&amp;author=Fahad%C2%A0Shahbaz+Khan&amp;publication_year=2023">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[15]</div><div id="Bib0015" class="citations"><div class="citation"><div class="citation-content">Jennifer R Mammen and Corey R Mammen. 2018. Beyond concept analysis: Uses of mind mapping software for visual representation, management, and analysis of diverse digital data. <em>Research in nursing &amp; health</em> 41, 6 (2018), 583–592.</div><div class="external-links"><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Beyond+concept+analysis%3A+Uses+of+mind+mapping+software+for+visual+representation%2C+management%2C+and+analysis+of+diverse+digital+data&amp;author=Jennifer%C2%A0R+Mammen&amp;author=Corey%C2%A0R+Mammen&amp;publication_year=2018&amp;pages=583-592">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[16]</div><div id="Bib0016" class="citations"><div class="citation"><div class="citation-content">OpenAI. 2023. GPT-4 Technical Report. arxiv:<a href="https://arXiv.org/abs/2303.08774" target="_blank">https://arXiv.org/abs/2303.08774</a> [cs.CL]</div><div class="external-links"><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=GPT-4+Technical+Report&amp;author=OpenAI&amp;publication_year=2023">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[17]</div><div id="Bib0017" class="citations"><div class="citation"><div class="citation-content">Fred Paas, Alexander Renkl, and John Sweller. 2003. Cognitive load theory and instructional design: Recent developments. <em>Educational psychologist</em> 38, 1 (2003), 1–4.</div><div class="external-links"><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Cognitive+load+theory+and+instructional+design%3A+Recent+developments&amp;author=Fred+Paas&amp;author=Alexander+Renkl&amp;author=John+Sweller&amp;publication_year=2003&amp;pages=1-4">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[18]</div><div id="Bib0018" class="citations"><div class="citation"><div class="citation-content">Adel Remadi, Karim El Hage, Yasmina Hobeika, and Francesca Bugiotti. 2024. To prompt or not to prompt: Navigating the use of large language models for integrating and modeling heterogeneous data. <em>Data &amp; Knowledge Engineering</em> 152 (2024), 102313.</div><div class="external-links"><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=To+prompt+or+not+to+prompt%3A+Navigating+the+use+of+large+language+models+for+integrating+and+modeling+heterogeneous+data&amp;author=Adel+Remadi&amp;author=Karim+El%C2%A0Hage&amp;author=Yasmina+Hobeika&amp;author=Francesca+Bugiotti&amp;publication_year=2024&amp;pages=102313">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[19]</div><div id="Bib0019" class="citations"><div class="citation"><div class="citation-content">Mark S Rosenbaum, Mauricio Losada Otalora, and Germán Contreras Ramírez. 2017. How to create a realistic customer journey map. <em>Business horizons</em> 60, 1 (2017), 143–150.</div><div class="external-links"><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=How+to+create+a+realistic+customer+journey+map&amp;author=Mark%C2%A0S+Rosenbaum&amp;author=Mauricio%C2%A0Losada+Otalora&amp;author=Germ%C3%A1n%C2%A0Contreras+Ram%C3%ADrez&amp;publication_year=2017&amp;pages=143-150">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[20]</div><div id="Bib0020" class="citations"><div class="citation"><div class="citation-content">Jesper Simonsen and Finn Kensing. 1997. Using ethnography in contextural design. <em>Commun. ACM</em> 40, 7 (1997), 82–88.</div><div class="external-links"><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Using+ethnography+in+contextural+design&amp;author=Jesper+Simonsen&amp;author=Finn+Kensing&amp;publication_year=1997&amp;pages=82-88">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[21]</div><div id="Bib0021" class="citations"><div class="citation"><div class="citation-content">Waralak Vongdoiwang Siricharoen. 2021. Using empathy mapping in design thinking process for personas discovering. In <em>Context-Aware Systems and Applications, and Nature of Computation and Communication: 9th EAI International Conference, ICCASA 2020, and 6th EAI International Conference, ICTCC 2020, Thai Nguyen, Vietnam, November 26–27, 2020, Proceedings 9</em>. Springer, 182–191.</div><div class="external-links"><div class="core-xlink-crossref"><a href="https://doi.org/10.1007/978-3-030-67101-3_15">Crossref</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Using+empathy+mapping+in+design+thinking+process+for+personas+discovering&amp;author=Waralak%C2%A0Vongdoiwang+Siricharoen&amp;publication_year=2021&amp;pages=182-191&amp;doi=10.1007%2F978-3-030-67101-3_15">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[22]</div><div id="Bib0022" class="citations"><div class="citation"><div class="citation-content">Peter W Szabo. 2017. <em>User experience mapping</em>. Packt Publishing Ltd.</div><div class="external-links"><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=User+experience+mapping&amp;author=Peter%C2%A0W+Szabo&amp;publication_year=2017">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[23]</div><div id="Bib0023" class="citations"><div class="citation"><div class="citation-content">Kuttimani Tamilmani, Nripendra P Rana, Samuel Fosso Wamba, and Rohita Dwivedi. 2021. The extended Unified Theory of Acceptance and Use of Technology (UTAUT2): A systematic literature review and theory evaluation. <em>International Journal of Information Management</em> 57 (2021), 102269.</div><div class="external-links"><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=The+extended+Unified+Theory+of+Acceptance+and+Use+of+Technology+%28UTAUT2%29%3A+A+systematic+literature+review+and+theory+evaluation&amp;author=Kuttimani+Tamilmani&amp;author=Nripendra%C2%A0P+Rana&amp;author=Samuel%C2%A0Fosso+Wamba&amp;author=Rohita+Dwivedi&amp;publication_year=2021&amp;pages=102269">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[24]</div><div id="Bib0024" class="citations"><div class="citation"><div class="citation-content">Deborah Tatar. 1989. Using video-based observation to shape the design of a new technology. <em>ACM SIGCHI Bulletin</em> 21, 2 (1989), 108–111.</div><div class="external-links"><div class="core-xlink-digital-library"><a href="/doi/10.1145/70609.70628">Digital Library</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Using+video-based+observation+to+shape+the+design+of+a+new+technology&amp;author=Deborah+Tatar&amp;publication_year=1989&amp;pages=108-111&amp;doi=10.1145%2F70609.70628">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[25]</div><div id="Bib0025" class="citations"><div class="citation"><div class="citation-content">Carmen Tomas, Emma Whitt, Rosa Lavelle-Hill, and Katie Severn. 2019. Modeling holistic marks with analytic rubrics. In <em>Frontiers in Education</em>, Vol. 4. Frontiers Media SA, 89.</div><div class="external-links"><div class="core-xlink-crossref"><a href="https://doi.org/10.3389/feduc.2019.00089">Crossref</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Modeling+holistic+marks+with+analytic+rubrics&amp;author=Carmen+Tomas&amp;author=Emma+Whitt&amp;author=Rosa+Lavelle-Hill&amp;author=Katie+Severn&amp;publication_year=2019&amp;pages=89&amp;doi=10.3389%2Ffeduc.2019.00089">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[26]</div><div id="Bib0026" class="citations"><div class="citation"><div class="citation-content">Laurie Vertelney. 1989. Using video to prototype user interfaces. <em>ACM SIGCHI Bulletin</em> 21, 2 (1989), 57–61.</div><div class="external-links"><div class="core-xlink-digital-library"><a href="/doi/10.1145/70609.70615">Digital Library</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Using+video+to+prototype+user+interfaces&amp;author=Laurie+Vertelney&amp;publication_year=1989&amp;pages=57-61&amp;doi=10.1145%2F70609.70615">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[27]</div><div id="Bib0027" class="citations"><div class="citation"><div class="citation-content">Anusha Vimalaksha, Siddarth Vinay, and NS Kumar. 2019. Hierarchical mind map generation from video lectures. In <em>2019 IEEE Tenth International Conference on Technology for Education (T4E)</em>. IEEE, 110–113.</div><div class="external-links"><div class="core-xlink-crossref"><a href="https://doi.org/10.1109/T4E.2019.00-40">Crossref</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Hierarchical+mind+map+generation+from+video+lectures&amp;author=Anusha+Vimalaksha&amp;author=Siddarth+Vinay&amp;author=NS+Kumar&amp;publication_year=2019&amp;pages=110-113&amp;doi=10.1109%2FT4E.2019.00-40">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[28]</div><div id="Bib0028" class="citations"><div class="citation"><div class="citation-content">Yilin Wen, Zifeng Wang, and Jimeng Sun. 2023. Mindmap: Knowledge graph prompting sparks graph of thoughts in large language models. <em>arXiv preprint arXiv:<a href="https://arXiv.org/abs/2308.09729" target="_blank">https://arXiv.org/abs/2308.09729</a></em> (2023).</div><div class="external-links"><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Mindmap%3A+Knowledge+graph+prompting+sparks+graph+of+thoughts+in+large+language+models&amp;author=Yilin+Wen&amp;author=Zifeng+Wang&amp;author=Jimeng+Sun&amp;publication_year=2023">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[29]</div><div id="Bib0029" class="citations"><div class="citation"><div class="citation-content">Bin Yin, Junjie Xie, Yu Qin, Zixiang Ding, Zhichao Feng, Xiang Li, and Wei Lin. 2023. Heterogeneous knowledge fusion: A novel approach for personalized recommendation via llm. In <em>Proceedings of the 17th ACM Conference on Recommender Systems</em>. 599–601.</div><div class="external-links"><div class="core-xlink-digital-library"><a href="/doi/10.1145/3604915.3608874">Digital Library</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Heterogeneous+knowledge+fusion%3A+A+novel+approach+for+personalized+recommendation+via+llm&amp;author=Bin+Yin&amp;author=Junjie+Xie&amp;author=Yu+Qin&amp;author=Zixiang+Ding&amp;author=Zhichao+Feng&amp;author=Xiang+Li&amp;author=Wei+Lin&amp;publication_year=2023&amp;pages=599-601&amp;doi=10.1145%2F3604915.3608874">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[30]</div><div id="Bib0030" class="citations"><div class="citation"><div class="citation-content">Salu Ylirisku and Jacob Buur. 2007. Making sense and editing videos. In <em>Designing with video: Focusing the user-centred design process</em>. Springer London, 86––135.</div><div class="external-links"><div class="core-xlink-crossref"><a href="https://doi.org/10.1007/978-1-84628-961-3_2">Crossref</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Making+sense+and+editing+videos&amp;author=Salu+Ylirisku&amp;author=Jacob+Buur&amp;publication_year=2007&amp;pages=86%E2%80%93%E2%80%93135&amp;doi=10.1007%2F978-1-84628-961-3_2">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[31]</div><div id="Bib0031" class="citations"><div class="citation"><div class="citation-content">Salu Ylirisku and Jacob Buur. 2007. Studying what people do. In <em>Designing with video: Focusing the user-centred design process</em>. Springer London, 36–85.</div><div class="external-links"><div class="core-xlink-crossref"><a href="https://doi.org/10.1007/978-1-84628-961-3_2">Crossref</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Studying+what+people+do&amp;author=Salu+Ylirisku&amp;author=Jacob+Buur&amp;publication_year=2007&amp;pages=36-85&amp;doi=10.1007%2F978-1-84628-961-3_2">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[32]</div><div id="Bib0032" class="citations"><div class="citation"><div class="citation-content">So Jung Yune, Sang Yeoup Lee, Sun Ju Im, Bee Sung Kam, and Sun Yong Baek. 2018. Holistic rubric vs. analytic rubric for measuring clinical performance levels in medical students. <em>BMC medical education</em> 18 (2018), 1–6.</div><div class="external-links"><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Holistic+rubric+vs.+analytic+rubric+for+measuring+clinical+performance+levels+in+medical+students&amp;author=So%C2%A0Jung+Yune&amp;author=Sang%C2%A0Yeoup+Lee&amp;author=Sun%C2%A0Ju+Im&amp;author=Bee%C2%A0Sung+Kam&amp;author=Sun%C2%A0Yong+Baek&amp;publication_year=2018&amp;pages=1-6">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[33]</div><div id="Bib0033" class="citations"><div class="citation"><div class="citation-content">JD Zamfirescu-Pereira, Richmond Y Wong, Bjoern Hartmann, and Qian Yang. 2023. Why Johnny can’t prompt: how non-AI experts try (and fail) to design LLM prompts. In <em>Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems</em>. 1–21.</div><div class="external-links"><div class="core-xlink-digital-library"><a href="/doi/10.1145/3544548.3581388">Digital Library</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Why+Johnny+can%E2%80%99t+prompt%3A+how+non-AI+experts+try+%28and+fail%29+to+design+LLM+prompts&amp;author=JD+Zamfirescu-Pereira&amp;author=Richmond%C2%A0Y+Wong&amp;author=Bjoern+Hartmann&amp;author=Qian+Yang&amp;publication_year=2023&amp;pages=1-21&amp;doi=10.1145%2F3544548.3581388">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[34]</div><div id="Bib0034" class="citations"><div class="citation"><div class="citation-content">Hang Zhang, Xin Li, and Lidong Bing. 2023. Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding. <em>arXiv preprint arXiv:<a href="https://arXiv.org/abs/2306.02858" target="_blank">https://arXiv.org/abs/2306.02858</a></em> (2023). <a href="https://arxiv.org/abs/2306.02858" target="_blank">https://arxiv.org/abs/2306.02858</a></div><div class="external-links"><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Video-LLaMA%3A+An+Instruction-tuned+Audio-Visual+Language+Model+for+Video+Understanding&amp;author=Hang+Zhang&amp;author=Xin+Li&amp;author=Lidong+Bing&amp;publication_year=2023">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[35]</div><div id="Bib0035" class="citations"><div class="citation"><div class="citation-content">Yan-lei Zhang, Shuang-jiu Xiao, Xu-bo Yang, and Lei Ding. 2010. Mind mapping based human memory management system. In <em>2010 International Conference on Computational Intelligence and Software Engineering</em>. IEEE, 1–4.</div><div class="external-links"><div class="core-xlink-crossref"><a href="https://doi.org/10.1109/CISE.2010.5676752">Crossref</a></div><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Mind+mapping+based+human+memory+management+system&amp;author=Yan-lei+Zhang&amp;author=Shuang-jiu+Xiao&amp;author=Xu-bo+Yang&amp;author=Lei+Ding&amp;publication_year=2010&amp;pages=1-4&amp;doi=10.1109%2FCISE.2010.5676752">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[36]</div><div id="Bib0036" class="citations"><div class="citation"><div class="citation-content">Jia-Hua Zhao and Qi-Fan Yang. 2023. Promoting international high-school students’ C hinese language learning achievements and perceptions: A mind mapping-based spherical video-based virtual reality learning system in C hinese language courses. <em>Journal of computer assisted learning</em> 39, 3 (2023), 1002–1016.</div><div class="external-links"><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=Promoting+international+high-school+students%E2%80%99+C+hinese+language+learning+achievements+and+perceptions%3A+A+mind+mapping-based+spherical+video-based+virtual+reality+learning+system+in+C+hinese+language+courses&amp;author=Jia-Hua+Zhao&amp;author=Qi-Fan+Yang&amp;publication_year=2023&amp;pages=1002-1016">Google Scholar</a></div></div></div></div></div><div role="listitem" data-has="label"><div class="label">[37]</div><div id="Bib0037" class="citations"><div class="citation"><div class="citation-content">Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al. 2023. A survey of large language models. <em>arXiv preprint arXiv:<a href="https://arXiv.org/abs/2303.18223" target="_blank">https://arXiv.org/abs/2303.18223</a></em> (2023).</div><div class="external-links"><div class="core-xlink-google-scholar"><a href="https://scholar.google.com/scholar_lookup?title=A+survey+of+large+language+models&amp;author=Wayne%C2%A0Xin+Zhao&amp;author=Kun+Zhou&amp;author=Junyi+Li&amp;author=Tianyi+Tang&amp;author=Xiaolei+Wang&amp;author=Yupeng+Hou&amp;author=Yingqian+Min&amp;author=Beichen+Zhang&amp;author=Junjie+Zhang&amp;author=Zican+Dong&amp;publication_year=2023">Google Scholar</a></div></div></div></div></div></div></section>









    
    
        <div data-widget-def="ux3-layout-widget" data-widget-id="5eab360b-b0a7-47ce-b05a-6e2d026cb5d0" id="ACM_widgets">
        



        
        <div>



        
        <div>









    
    
        <div data-widget-def="UX3CitedByWidget" data-widget-id="fbd0b7aa-930a-4342-a3da-6e5f895c5500" class="cited-by__article-body">
        



        
        <section class="cited-by"><div class="cited-by__wrapper"><div class="flex justify-between mb-2 align-items-c colored-block__title"><h2 class="cited-by__title left-bordered-title">Cited By</h2><a href="/action/ajaxShowCitedBy?doi=10.1145/3706599.3719940" target="_blank" title="View all cited by in new tab" class="downloadAll btn blue">View all<i class="icon-export"></i></a></div><div id="cited-by__content" data-source="" class="cited-by__content"></div><ul data-pageSize="3" data-more="Show More Cited By" data-total='1' class="rlist separator cited-by__list"><li class="citedByEntry"><span class="entryAuthor"><span class="comma-separator">Tang K</span><span class="comma-separator">Chen K</span><span class="comma-separator">Jiang Z</span><span class="comma-separator">Quinlan M</span><span class="comma-separator">Cho Y</span></span><span class="pub-date dot-after">(2025)</span><span>Exploring LLM Agents as Interactive Mind Map Creators Tailored for Students with ADHD</span><span class="seriesTitle">Adjunct Proceedings of the 38th Annual ACM Symposium on User Interface Software and Technology</span><span class="doi">10.1145/3746058.3759012</span><span class="page-range">(1-6)</span><span class="pub-date">Online publication date: 28-Sep-2025</span><div class="extra-links pt-3"><a href="https://dl.acm.org/doi/10.1145/3746058.3759012" target="_blank" class="link">https://dl.acm.org/doi/10.1145/3746058.3759012</a></div></li></ul></div></section>

        </div>
    

</div>










    
    
        <section data-widget-def="ux3-layout-widget" data-widget-id="39967302-8491-456d-8cd5-f2724d18d392" id="sec-terms">
        



        
        <div>









    
    
        <div data-widget-def="UX3TagWidget" data-widget-id="e2ef85cc-92e2-4a74-b049-e0a086481942" class="citation article__section article__index-terms">
        



        
        



        
        <h2>Index Terms</h2>

<ol class="rlist organizational-chart"><li><div id="organizational-chart__title">"A Great Start, But...": Evaluating LLM-Generated Mind Maps for Information Mapping in Video-Based Design</div><ol class="rlist level-1  ch-2 hasNodes"><li><div data-background="#757575" style="background-color:#757575;box-shadow:none"><p><a href="/topic/ccs2012/10010147?ContentGroupKey=10.1145%2F3706599&amp;expand=all">Computing methodologies</a></p></div><ol class="rlist level-2 ch-1 hasNodes"><li><div data-background="#757575" style="background-color:#757575;box-shadow:none"><p><a href="/topic/ccs2012/10010147.10010178?ContentGroupKey=10.1145%2F3706599&amp;expand=all">Artificial intelligence</a></p></div><ol class="rlist level-3 ch-1 hasNodes"><li><div data-background="#757575" style="background-color:#757575;box-shadow:none"><p><a href="/topic/ccs2012/10010147.10010178.10010199?ContentGroupKey=10.1145%2F3706599&amp;expand=all">Planning and scheduling</a></p></div><ol class="rlist level-4 ch-1 hasNodes"><li><div data-background="#757575" style="background-color:#757575;box-shadow:none"><p><a href="/topic/ccs2012/10010147.10010178.10010199.10010200?ContentGroupKey=10.1145%2F3706599&amp;expand=all">Planning for deterministic actions</a></p></div><ol class="rlist level-5 ch-0"></ol></li></ol></li></ol></li></ol></li><li><div data-background="#757575" style="background-color:#757575;box-shadow:none"><p><a href="/topic/ccs2012/10003120?ContentGroupKey=10.1145%2F3706599&amp;expand=all">Human-centered computing</a></p></div><ol class="rlist level-2 ch-1 hasNodes"><li><div data-background="#757575" style="background-color:#757575;box-shadow:none"><p><a href="/topic/ccs2012/10003120.10003121?ContentGroupKey=10.1145%2F3706599&amp;expand=all">Human computer interaction (HCI)</a></p></div><ol class="rlist level-3 ch-1 hasNodes"><li><div data-background="#757575" style="background-color:#757575;box-shadow:none"><p><a href="/topic/ccs2012/10003120.10003121.10011748?ContentGroupKey=10.1145%2F3706599&amp;expand=all">Empirical studies in HCI</a></p></div><ol class="rlist level-4 ch-0"></ol></li></ol></li></ol></li></ol></li></ol>

        </div>
    











    
    
        <div data-widget-def="graphQueryWidget" data-widget-id="a0e1f283-de80-413e-bd95-25e0e7f29726" class="disclaimer">
        



        
        

        </div>
    

</div>

        </section>
    











    
    
        <section data-widget-def="ux3-layout-widget" data-widget-id="05703002-6a13-4f45-bf69-ef3358f44bf6" id="sec-recommendations">
        



        
        <div>



        
        <h2>Recommendations</h2> 




        
        <div class="show-recommended"><div data-exp-type="" data-query-id="10.1145/3706599.3719940" class="recommended-articles__content"><ul class="rlist lot"><li class="grid-item"><div class="creative-work"><a href="/doi/10.1145/2034691.2034709" title="An exploratory analysis of mind maps"><h3 data-lines="2" class="creative-work__title truncate-text-css">An exploratory analysis of mind maps</h3></a><div class="creative-work__sub-title mb-3 mt-1">DocEng '11: Proceedings of the 11th ACM symposium on Document engineering  </div><div class="description"><div class="issue-item__abstract truncate-text-css" data-lines="4">
   		
   <p>The results presented in this paper come from an exploratory study of 19,379 mind
      maps created by 11,179 users from the mind mapping applications 'Docear' and 'MindMeister'.
      The objective was to find out how mind maps are structured and which ...</p>
</div></div><div class="readMore"><a href="/doi/10.1145/2034691.2034709" title="Read More" aria-hidden="true" tabindex="-1">Read More</a></div></div></li><li class="grid-item"><div class="creative-work"><a href="/doi/10.5555/518910.850404" title="Mapping Information onto 3D Virtual Worlds"><h3 data-lines="2" class="creative-work__title truncate-text-css">Mapping Information onto 3D Virtual Worlds</h3></a><div class="creative-work__sub-title mb-3 mt-1">IV '00: Proceedings of the International Conference on Information Visualisation  </div><div class="description"><div class="issue-item__abstract truncate-text-css" data-lines="4">
   		
   <p>This paper presents a strategy for automatically mapping information onto visual parameters
      in the field of three-dimensional (3D) information visualization. The work presented
      here is done in the context of researching how 3D information visualization ...</p>
</div></div><div class="readMore"><a href="/doi/10.5555/518910.850404" title="Read More" aria-hidden="true" tabindex="-1">Read More</a></div></div></li><li class="grid-item"><div class="creative-work"><a href="/doi/10.1145/1810617.1810686" title="Enhancing search applications by utilizing mind maps"><h3 data-lines="2" class="creative-work__title truncate-text-css">Enhancing search applications by utilizing mind maps</h3></a><div class="creative-work__sub-title mb-3 mt-1">HT '10: Proceedings of the 21st ACM conference on Hypertext and hypermedia  </div><div class="description"><div class="issue-item__abstract truncate-text-css" data-lines="4">
   		
   <p>In this paper we present how sharing and utilizing mind maps could enhance search
      applications such as document search engines and recommender systems. In addition,
      we briefly present the first research results which indicate that mind maps can be
      used ...</p>
</div></div><div class="readMore"><a href="/doi/10.1145/1810617.1810686" title="Read More" aria-hidden="true" tabindex="-1">Read More</a></div></div></li></ul></div></div>
</div>

        </section>
    











    
    
        <section data-widget-def="ux3-layout-widget" data-widget-id="f58d89db-f506-4530-9812-61749ee9f921" id="sec-comments">
        



        
        <div>



        
        <h2>Comments</h2>




        
        <div id="disqus_thread" data-page-identifier="10.1145/3706599.3719940" data-remote-auth="" data-api-key="MmWj4FlWmXk20FJsmWMXbTJoZT7TVzTsc9Rw0yrJp3L1ZNXZuvmxF3F5rFIF8RqQ" data-forum-shortname="acm-prod"></div><a href="https://dl.acm.org/doi/10.1145/3706599.3719940#disqus_thread" class="disqus-count hidden"></a><noscript>Please enable JavaScript to view the<a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
</div>

        </section>
    

</div>

        </div>
    

</div></section></div><div class="core-collateral" role="dialog" aria-modal="true"><div id="core-collateral-info" aria-expanded="false"><header><h2><i class="icon-Icon_Information" aria-hidden="true"></i>Information &amp; Contributors</h2></header><section id="tab-information" role="tabpanel"><h3>Information</h3><section class="core-self-citation"><h4>Published In</h4>



        
        <div class="cover-image"><div class="cover-image__image"><img src="/specs/products/acm/releasedAssets/images/Default_image_lazy-0687af31f0f1c8d4b7a22b686995ab9b.svg" data-src="/cms/asset/9ff8084f-ead3-4316-a709-04124a22e308/3706599.cover.jpg" alt="cover image ACM Conferences" height="711" width="550" class="lazy"/></div><div class="cover-image__details"><div class="book-meta">CHI EA '25: Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems</div><div class="cover-date">April 2025</div><div class="cover-pages">7138  pages</div><div class="cover-image__details-extra"><div class="flex-container"><span class="bold">ISBN:</span><span class="space">9798400713958</span></div><div class="flex-container"><span class="bold">DOI:</span><span class="space">10.1145/3706599</span></div><div class="flex-container"><div><ul class="rlist--inline loa truncate-list" title="list of authors" data-lines="2"><li class="label"><b>Editors: </b></li><li><a href="/profile/99661567625" title="Naomi Yamashita"><img class="author-picture" src="/pb-assets/icons/DOs/default-profile-1543932446943.svg" width="24" height="24" alt="Author Picture" aria-hidden="true"/><span>Naomi Yamashita</span></a><span class="loa_author_inst hidden"><p data-doi="10.1145/contrib-99661567625">Kyoto University / NTT</p></span><span>,</span></li><li><a href="/profile/81100133286" title="Vanessa Evers"><img class="author-picture" src="/action/showDoPubAsset?doi=10.1145/contrib-81100133286&format=rel-imgonly&assetId=vanessa-1.jpg" width="24" height="24" alt="Author Picture" aria-hidden="true"/><span>Vanessa Evers</span></a><span class="loa_author_inst hidden"><p data-doi="10.1145/contrib-81100133286">University of Twente / Nanyang Technological University</p></span><span>,</span></li><li><a href="/profile/81100158260" title="Koji Yatani"><img class="author-picture" src="/action/showDoPubAsset?doi=10.1145/contrib-81100158260&format=rel-imgonly&assetId=me_202010.jpg" width="24" height="24" alt="Author Picture" aria-hidden="true"/><span>Koji Yatani</span></a><span class="loa_author_inst hidden"><p data-doi="10.1145/contrib-81100158260">The University of Tokyo</p></span><span>,</span></li><li><a href="/profile/99661566428" title="Xianghua (Sharon) Ding"><img class="author-picture" src="/pb-assets/icons/DOs/default-profile-1543932446943.svg" width="24" height="24" alt="Author Picture" aria-hidden="true"/><span>Xianghua (Sharon) Ding</span></a><span class="loa_author_inst hidden"><p data-doi="10.1145/contrib-99661566428">University of Glasgow</p></span></li></ul></div></div></div><div class="pb-dropzone" data-pb-dropzone="metadataDisplayExtra" title="metadataDisplayExtra"></div></div></div>
<div role="paragraph" class="core-copyright">Copyright © 2025 Copyright held by the owner/author(s).</div><div class="core-license">Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s).</div></section><section class="core-sponsors"><h4>Sponsors</h4><ul><li><a href="/sig/sigchi">SIGCHI: ACM Special Interest Group on Computer-Human Interaction</a></li></ul></section><section class="core-publisher"><h4>Publisher</h4><div class="section__content"><div class="publisher__details"><p class="publisher__name">Association for Computing Machinery</p><p class="publisher__address">New York, NY, United States</p></div></div></section><section id="core-history" class="core-history"><h4>Publication History</h4><div><b class="core-label">Published</b>: 25 April 2025</div></section><section class="core-collateral-crossmark"><h4>Check for updates</h4><a data-target="crossmark" href="#" title="Check for updates on crossmark" data-doi="10.1145/3706599.3719940" data-id="article-info-crossmark" class="crossmark__link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" height="36px" role="presentation"><rect x="5" y="5" width="90" height="90" rx="2" ry="2" class="cls-1"></rect><polygon points="35.95 65.11 64.05 46.38 64.05 23.91 35.95 23.91 35.95 65.11" class="cls-2"></polygon><polygon points="64.05 65.11 35.95 46.38 35.95 23.91 64.05 23.91 64.05 65.11" class="cls-3"></polygon><path d="M50,19A31,31,0,1,0,81,50,31,31,0,0,0,50,19Zm0,54.41A23.41,23.41,0,1,1,73.41,50,23.41,23.41,0,0,1,50,73.41Z" class="cls-4"></path><path d="M67.18,65.86a23.38,23.38,0,0,1-38.9-24.57l-6.49-4.1A31,31,0,0,0,73.69,70Z" class="cls-5"></path><defs><style>.cls-1{stroke:#948f8f;stroke-miterlimit:10;stroke-width:0.75px;fill:url(#no_text_crossmark);}
.cls-2{fill:#c72914;}
.cls-3{fill:#ef3340;}
.cls-4{fill:#3eb1c8;}
.cls-5{fill:#ffc72c;}</style><linearGradient id="no_text_crossmark" x1="50" y1="15.18" x2="50" y2="94.72" gradientUnits="userSpaceOnUse"><stop stop-color="#fff"></stop><stop offset="1" stop-color="#c4c4c4"></stop></linearGradient></defs></svg></a></section><section property="keywords"><h4>Author Tags</h4><ol><li><a href="/keyword/Information+Mapping?expand=all" alt="Search on this keyword" rel="nofollow">Information Mapping</a></li><li><a href="/keyword/Large+Language+Model?expand=all" alt="Search on this keyword" rel="nofollow">Large Language Model</a></li><li><a href="/keyword/Video-based+Design?expand=all" alt="Search on this keyword" rel="nofollow">Video-based Design</a></li><li><a href="/keyword/Designer-AI+Collaboration?expand=all" alt="Search on this keyword" rel="nofollow">Designer-AI Collaboration</a></li></ol></section><section class="core-qualifiers"><h4>Qualifiers</h4><ul><li>Work in progress</li></ul></section><section class="core-conference"><h4>Conference</h4><div class="core-conference-left"><span class="core-conference-code">CHI EA '25</span><div class="core-conference-sponsors"><span class="core-conference-sponsors-label">Sponsor:</span><ul class="core-conference-sponsors-list truncate-list" data-lines="2"><li class="core-sponsors-list-item"><a href="/sig/sigchi">SIGCHI</a></li></ul></div></div><div class="core-conference-right"><a href="https://chi2025.acm.org/">CHI EA '25: Extended Abstracts of the CHI Conference on Human Factors in Computing Systems</a><div class="core-conference-calender"><i class="icon-calender3"></i><span class="core-conference-date">April 26 - May 1, 2025</span></div><div class="core-conference-map"><i class="icon-navigator"></i>Yokohama, Japan</div></div></section>



        
        <div class="acceptance-rates__section"><h4 aria-expanded="true">Acceptance Rates</h4><div class="accordion-tabbed__content"><div class="acceptance-rates__heading"><div class="acceptance-rates__heading-overall">Overall Acceptance Rate 6,164 of 23,696 submissions, 26%</div></div></div></div>




        
        






<div class="upcoming-conf">
<h4>Upcoming Conference</h4>
    <div class="section__content">
        <div class="event event--inline-info row--event active">
        <input type="hidden" name="Longitude" value="2.219339"/>
        <input type="hidden" name="Latitude" value="41.408845"/>
        <input type="hidden" name="StartDate" value="2026-04-13T00:00:00.000+01:00">
        <input type="hidden" name="EndDate" value="2026-04-17T00:00:00.000+01:00">  
            <div class="event__header clearfix">
                <div class="left--block gutterless">
                    <span class="event__code">
                        <span class="event__code--text">CHI '26</span>
                    </span>
                    
                        <div class="event__sopnsers">
                            <ul data-lines="3" class="rlist truncate-list">
                                <li class="label"><b>Sponsor:</b></li>
                                
                                    
                                        <li style="text-transform: uppercase;">
                                            <a class="link" href="/sig/sigchi" title="Special Interest Group on Computer-Human Interaction"><span class="hlFld-Title">sigchi</span></a>
										</li>
											
								
                            </ul>
                        </div>
                        
                </div>
                <div class="right--block">
                    
                        
                            <a class="event__title" href="/conference/chi" title="ACM CHI Conference on Human Factors in Computing Systems">ACM CHI Conference on Human Factors in Computing Systems</a>                                
                        
                    
                        
                     
                    <div class="event__content">
                        <div class="info calender">
                            <a href="http://www.google.com/calendar/event?action=TEMPLATE&amp;text=ACM CHI Conference on Human Factors in Computing Systems&amp;dates=20260413/20260417&amp;details=ACM CHI Conference on Human Factors in Computing Systems&amp;location=Barcelona%2C%20%2C%20Spain" target="_blank">
                                    <i class="icon-add-calendar"></i>
                            </a>
                            <span>
                                April 13 - 17, 2026
                            <span>
                        </div>
                        <div class="info map">
                            <a href="https://maps.google.com/?q=Barcelona,, Spain" target="_blank">
                                <i class="icon-navigator"></i>
                            </a>
                            <span>
                                
                                    Barcelona ,
                                
                                 
                                
                                    Spain       
                                
                            </span>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

</section><section id="tab-contributors" role="tabpanel"><h3>Contributors</h3>









    
    
        <div data-widget-def="acmPublicationContributorsWidget" data-widget-id="774172a5-8222-4087-8d6e-7a1a17ded31e" class="expandable-accordion">
        



        
        <div class="publication-contribs-contianer"><input id="ContribsAjax" type="hidden" data-ajax="/pb/widgets/getContribs?widgetId=774172a5-8222-4087-8d6e-7a1a17ded31e&amp;pbContext=%3Btopic%3Atopic%3Aconference-collections%26gt%3Bchi%3Btaxonomy%3Ataxonomy%3Aconference-collections%3Bwgroup%3Astring%3AACM+Publication+Websites%3Bissue%3Aissue%3Adoi%5C%3A10.1145%2F3706599%3BgroupTopic%3Atopic%3Aacm-pubtype%26gt%3Bproceeding%3Bctype%3Astring%3ABook+Content%3BsubPage%3Astring%3AFull+Text%3Barticle%3Aarticle%3Adoi%5C%3A10.1145%2F3706599.3719940%3Bpage%3Astring%3AArticle%2FChapter+View%3Bcsubtype%3Astring%3AConference+Proceedings%3Bwebsite%3Awebsite%3Adl-site%3Bjournal%3Ajournal%3Aacmconferences%3BpageGroup%3Astring%3APublication+Pages"/><div class="loader"><img src="/specs/products/acm/releasedAssets/images/loader-7e60691fbe777356dc81ff6d223a82a6.gif"/></div></div>

        </div>
    

<section><h4 class="left-bordered-title">Other Metrics</h4><div class="otherMetrics__section__content"><a href="#tab-metrics-inner" data-tab="pill-bibliometrics__content" data-label="Bibliometrics &amp; Citations" class="btn btn--inverse tab-link stretched">View Article Metrics</a></div></section></section></div><div id="core-collateral-metrics" aria-expanded="false"><header><h2><i class="icon-metric" aria-hidden="true"></i>Bibliometrics &amp; Citations</h2></header><section id="tab-metrics-inner" role="tabpanel"><h3>Bibliometrics</h3><section>



        
            <h4 class="">
                Article Metrics
            </h4>
        
        <div class="pill-bibliometrics__content"><div class="section__content"><ul class="rlist--inline article-metrics"><li><div class="article-metric citation"><div class="metric-value"><span>1</span></div>Total Citations</div><a href="#tab-citations" class="primary-blue-color tab-link slide-active pill-content">View Citations</a></li><li><div class="article-metric download"><div class="metric-value"><span>454</span></div>Total Downloads</div></li></ul><ul class="rlist metrics__list"><li><span class="metric-name">Downloads (Last 12 months)</span><span class="metric-value">454</span></li><li><span class="metric-name">Downloads (Last 6 weeks)</span><span class="metric-value">98</span></li></ul><div class="metric-update"><span class="metric-update__date">Reflects downloads up to 04 Nov 2025</span></div></div></div>
</section><section></section><section><h4 class="left-bordered-title">Other Metrics</h4><div class="otherMetrics__section__content"><a href="#tab-contributors" data-tab="pill-authors__content" data-label="Information &amp; Authors" class="btn btn--inverse tab-link stretched">View Author Metrics</a></div></section></section><section id="tab-citations" role="tabpanel"><h3>Citations</h3><section></section><section>



        
        <section class="cited-by"><div class="cited-by__wrapper"><div class="flex justify-between mb-2 align-items-c colored-block__title"><h2 class="cited-by__title left-bordered-title">Cited By</h2><a href="/action/ajaxShowCitedBy?doi=10.1145/3706599.3719940" target="_blank" title="View all cited by in new tab" class="downloadAll btn blue">View all<i class="icon-export"></i></a></div><div id="cited-by__content" data-source="" class="cited-by__content"></div><ul data-pageSize="10" data-more="Show More Cited By" data-total='1' class="rlist separator cited-by__list"><li class="citedByEntry"><span class="entryAuthor"><span class="comma-separator">Tang K</span><span class="comma-separator">Chen K</span><span class="comma-separator">Jiang Z</span><span class="comma-separator">Quinlan M</span><span class="comma-separator">Cho Y</span></span><span class="pub-date dot-after">(2025)</span><span>Exploring LLM Agents as Interactive Mind Map Creators Tailored for Students with ADHD</span><span class="seriesTitle">Adjunct Proceedings of the 38th Annual ACM Symposium on User Interface Software and Technology</span><span class="doi">10.1145/3746058.3759012</span><span class="page-range">(1-6)</span><span class="pub-date">Online publication date: 28-Sep-2025</span><div class="extra-links pt-3"><a href="https://dl.acm.org/doi/10.1145/3746058.3759012" target="_blank" class="link">https://dl.acm.org/doi/10.1145/3746058.3759012</a></div></li></ul></div></section>
</section></section></div><div id="core-collateral-fulltext-options" aria-expanded="false"><header><h2><i class="icon-eye" aria-hidden="true"></i>View Options</h2></header><div data-mark="default" class="section--wrapper"><h3>View options</h3><section class="format--pdf"><h4> <abbr title="Portable Document Format">PDF</abbr></h4><p>View or Download as a PDF file.</p><a href="https://dl.acm.org/doi/pdf/10.1145/3706599.3719940" class="btn btn--pdf red" aria-label="View PDF" title="View PDF"><i aria-hidden="true" class="icon-pdf-file"></i><span>PDF</span></a></section><section class="format--epdf"><h4> <abbr title="Electronic Reader">eReader</abbr></h4><p>View online with <abbr title="Electronic Reader">eReader</abbr>.</p><a href="/doi/epdf/10.1145/3706599.3719940" class="btn btn--eReader blue" aria-label="View online with eReader" title="View online with eReader"><i aria-hidden="true" class="icon-eReader"></i><span><abbr title="Electronic Reader">eReader</abbr></span></a></section></div><div data-mark="pageBuilder" class="section--wrapper"><section>



        
        <div class="get__access"><div class="mb-4"><h4>Login options</h4><div class="get__access__login pt-3 pb-4"><p class="info--text">Check if you have access through your login credentials or your institution to get full access on this article.</p><a title="Sign in" href="/action/showLogin?redirectUri=%2Fdoi%2F10.1145%2F3706599.3719940" class="btn big btn--inverse">Sign in</a></div></div><div><h4>Full Access</h4><div class="get__access__full__access py-3"><a href="/action/publisherEcommerceHelper?doi=10.1145/3706599.3719940&amp;redirectUri=https://dl.acm.org/doi/10.1145/3706599.3719940" title="Get this Publication" class="btn blue big false">Get this Publication</a></div></div></div>
</section><section></section></div></div><div id="core-collateral-figures" aria-expanded="false"><header><h2><i class="icon-Icon_Images" aria-hidden="true"></i>Figures</h2></header><!-- There is no content. --></div><div id="core-collateral-tables" aria-expanded="false"><header><h2><i class="icon-table" aria-hidden="true"></i>Tables</h2></header><!-- There is no content. --></div><div id="core-collateral-media" aria-expanded="false"><header><h2><i class="icon-play-circle-filled" aria-hidden="true"></i>Media</h2></header><!-- There is no content. --></div><div id="core-collateral-share" aria-expanded="false"><header><h2><i class="icon-Icon_Share" aria-hidden="true"></i>Share</h2></header><h3>Share</h3><div class="section--wrapper"><section><h4>Share this Publication link</h4><div id="share-self"><p data-id="article-share-self-link" class="share-self__source"></p><button data-id="article-share-access" aria-label="Copy the content Link" class="share-self__action btn btn--inverse"><i aria-hidden="true" class="icon-pages"></i><span>Copy Link</span></button><div aria-live="polite" class="share-self__status"><p class="share-self__success"><i aria-hidden="true" class="icon-check_circle"></i><span>Copied!</span></p><p class="share-self__failed"><i aria-hidden="true" class="icon-x_btnclose"></i><span>Copying failed.</span></p></div></div></section><section><h4>Share on social media</h4><div class="share-buttons a2a a2a_kit"><a href="#" aria-label="Share on X" data-id="article-share-twitter" rel="nofollow noopener" role="link" target="_blank" title="Share on X" class="btn btn--twitter a2a_button_twitter"><i aria-hidden="true" class="icon-x"></i><span>X</span></a><a href="#" aria-label="Share on LinkedIn" data-id="article-share-linkedin" rel="nofollow noopener" role="link" target="_blank" title="Share on LinkedIn" class="btn btn--linkedin a2a_button_linkedin"><i aria-hidden="true" class="icon-linkedin"></i><span>LinkedIn</span></a><a href="#" aria-label="Share on Reddit" data-id="article-share-reddit" rel="nofollow noopener" role="link" target="_blank" title="Share on Reddit" class="btn btn--reddit a2a_button_reddit"><i aria-hidden="true" class="icon-reddit-filled"></i><span>Reddit</span></a><a href="#" aria-label="Share on Facebook" data-id="article-share-facebook" rel="nofollow noopener" role="link" target="_blank" title="Share on Facebook" class="btn btn--facebook a2a_button_facebook"><i aria-hidden="true" class="icon-Icon_Facebook"></i><span>Facebook</span></a><a href="#" aria-label="Share on email" data-id="article-share-email" rel="nofollow noopener" role="link" target="_blank" title="Share on email" class="btn btn--email a2a_button_email"><i aria-hidden="true" class="icon-Icon_mail"></i><span>email</span></a></div></section></div></div></div><aside data-core-aside="right-rail">



        
        <div class="col-md-12 col-sm-6">



        
        



    

    

    
        
    






        
        



    

    

    
        
    






        
        



    

    

    
        
    


</div>
</aside><div class="contributors-with-details" style="display:none"><section class="core-authors"><h4>Affiliations</h4><div id="artseq-00001" property="author" typeof="Person" data-doi="10.1145/contrib-99661569134"><div class="heading"><img src="/pb-assets/icons/DOs/default-profile-1543932446943.svg" class="core-profile-image" role="presentation" /><div property="name"><span property="givenName">Tianhao</span> <span property="familyName">He</span></div></div><div class="content"><div class="affiliations"><div property="affiliation" typeof="Organization"><span property="name">Design at Scale Lab (D@S Lab), Delft University of Technology, Delft, Netherlands <a href="/cdn-cgi/l/email-protection#88fca6e0eda5b9c8fcfdecede4eefca6e6e4" property="email" aria-label="Email address"><span class="__cf_email__" data-cfemail="99edb7f1fcb4a8d9edecfdfcf5ffedb7f7f5">[email&#160;protected]</span></a></span></div></div><div class="core-orcid-link"><a href="https://orcid.org/0000-0002-8486-3940" target="_blank" aria-label="ORCID identifier">https://orcid.org/0000-0002-8486-3940</a></div><div class="core-author-link"><a href="/profile/99661569134" rel="nofollow" class="profile-link">View Profile</a></div></div></div><div id="artseq-00002" property="author" typeof="Person" data-doi="10.1145/contrib-99661565842"><div class="heading"><img src="/pb-assets/icons/DOs/default-profile-1543932446943.svg" class="core-profile-image" role="presentation" /><div property="name"><span property="givenName">Karthi</span> <span property="familyName">Saravanan</span></div></div><div class="content"><div class="affiliations"><div property="affiliation" typeof="Organization"><span property="name">Faculty of Industrial Design Engineering, Delft University of Technology, Delft, Netherlands <a href="/cdn-cgi/l/email-protection#f79c9685839f9ed984d99891919e949e969bb7909a969e9bd994989a" property="email" aria-label="Email address"><span class="__cf_email__" data-cfemail="640f0516100c0d4a174a0b02020d070d0508240309050d084a070b09">[email&#160;protected]</span></a></span></div></div><div class="core-orcid-link"><a href="https://orcid.org/0009-0008-4986-7760" target="_blank" aria-label="ORCID identifier">https://orcid.org/0009-0008-4986-7760</a></div><div class="core-author-link"><a href="/profile/99661565842" rel="nofollow" class="profile-link">View Profile</a></div></div></div><div id="artseq-00003" property="author" typeof="Person" data-doi="10.1145/contrib-81548019687"><div class="heading"><img src="/action/showDoPubAsset?doi=10.1145/contrib-81548019687&amp;format=rel-imgonly&amp;assetId=evanpicsmall.png" class="core-profile-image" role="presentation" /><div property="name"><span property="givenName">Evangelos</span> <span property="familyName">Niforatos</span></div></div><div class="content"><div class="affiliations"><div property="affiliation" typeof="Organization"><span property="name">Faculty of Industrial Design Engineering, Delft University of Technology, Delft, Netherlands <a href="/cdn-cgi/l/email-protection#e287cc8c8b848d9083968d91a2969786878e8496cc8c8e" property="email" aria-label="Email address"><span class="__cf_email__" data-cfemail="365318585f5059445742594576424352535a504218585a">[email&#160;protected]</span></a></span></div></div><div class="core-orcid-link"><a href="https://orcid.org/0000-0002-0484-4214" target="_blank" aria-label="ORCID identifier">https://orcid.org/0000-0002-0484-4214</a></div><div class="core-author-link"><a href="/profile/81548019687" rel="nofollow" class="profile-link">View Profile</a></div></div></div><div id="artseq-00004" property="author" typeof="Person" data-doi="10.1145/contrib-81100146541"><div class="heading"><img src="/pb-assets/icons/DOs/default-profile-1543932446943.svg" class="core-profile-image" role="presentation" /><div property="name"><span property="givenName">Gerd</span> <span property="familyName">Kortuem</span></div></div><div class="content"><div class="affiliations"><div property="affiliation" typeof="Organization"><span property="name">Faculty of Industrial Design Engineering, Delft University of Technology, Delft, Netherlands <a href="/cdn-cgi/l/email-protection#c5a2ebb2ebaeaab7b1b0a0a885b1b0a1a0a9a3b1ebaba9" property="email" aria-label="Email address"><span class="__cf_email__" data-cfemail="197e376e3772766b6d6c7c74596d6c7d7c757f6d377775">[email&#160;protected]</span></a></span></div></div><div class="core-orcid-link"><a href="https://orcid.org/0000-0003-3500-0046" target="_blank" aria-label="ORCID identifier">https://orcid.org/0000-0003-3500-0046</a></div><div class="core-author-link"><a href="/profile/81100146541" rel="nofollow" class="profile-link">View Profile</a></div></div></div></section></div></article><div data-extent="article-wrapper"><div class="core-container"></div><div class="after-credits"><div class="core-container"><a href="/doi/full/10.1145/3706599.3719940"><span>View full text</span></a><span class="spacer">|</span><a href="/doi/pdf/10.1145/3706599.3719940?download=true" id="downloadPdfUrl" data-doi="10.1145/3706599.3719940"><span>Download PDF</span></a></div></div></div><script data-cfasync="false" src="/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script id="axel-publication-metadata" type="application/json">{"doi":"10.1145/3706599.3719940","type":"Chapter"}
</script><script type="text/javascript" data-ot-ignore="data-ot-ignore" defer="defer" src="https://static.addtoany.com/menu/page.js" class="optanon-category-C0004 ot-vscat-C0004"></script><template id="core_texts_template" data-goto="Go to ##" data-gotographic="Go to Figure" data-gototable="Go to Table" data-gotomedia="Go to Media" data-openall="Open all in viewer" data-openspecific="Open ## in Viewer" data-opengeneric="Open in Viewer" data-citations-goto="Go to Citation" data-citations-toggle="Toggle citations menu" data-citations-links="Citations links" data-citations-hide="Hide Citations" data-citations-show="Show Citations" data-footnotes-goto="Go to Footnote" data-footnotes-toggle="Toggle footnotes menu" data-footnotes-links="Footnotes links" data-footnotes-hide="Hide Footnotes" data-footnotes-show="Show Footnotes"></template><div role="navigation" aria-label="Sticky Navigation" class="st-header-acm"><div class="st-header__track"><div id="progress-tracker" class="st-header__tracker"></div></div></div><template id="fv_skeleton_template" data-overlay="View figure"><div role="dialog" aria-modal="true" aria-label="Figure Viewer" hidden="hidden" class="core-fv"><div role="region" hidden="hidden" class="core-fv__directory"><header aria-label="Category Tabs Toolbar" class="core-fv__toolbar"><div role="tablist" aria-label="Figure Viewer Category Tabs"><button role="tab" aria-selected="false" aria-controls="core-fv-panel_graphic" id="core-fv__graphic-tab" class="core-fv__btn"><span>Figures</span></button><button role="tab" aria-selected="false" aria-controls="core-fv-panel_table" id="core-fv__table-tab" class="core-fv__btn"><span>Tables</span></button></div><button role="button" class="core-fv__close core-fv__btn" title="Close"><i aria-hidden="true" class="icon-close_thin"></i><span class="sr-only">Close figure viewer</span></button></header><main aria-label="Selected Category Content" class="core-fv__content"><div role="tabpanel" id="core-fv-panel_graphic" aria-labelledby="core-fv__graphic-tab"></div><div role="tabpanel" id="core-fv-panel_table" aria-labelledby="core-fv__table-tab"></div></main></div><div role="region" data-zoomed="false" hidden="hidden" class="core-fv__lightbox"><header aria-label="Figure Viewer Toolbar" class="core-fv__toolbar"><button role="button" class="core-fv__close core-fv__btn"><i aria-hidden="true" class="icon-arrow_l"></i><span>Back to article</span></button><div id="core-fv__toolbar__info" class="core-fv__toolbar__info">Figure title goes here</div><div class="core-fv__toolbar__holster"><div data-visible-on="graphic table"><button role="button" class="core-fv__zoom  core-fv__btn" title="Change zoom level"><i data-zoom="in" aria-hidden="true" class="icon-zoom-in"></i><i data-zoom="out" aria-hidden="true" class="icon-zoom-out"></i><span class="sr-only">Change zoom level</span></button></div><div data-visible-on="graphic table media"><a href="#f1" class="core-fv__back core-fv__back-to-original core-fv__btn" title="Go to figure location within the article"><i aria-hidden="true" class="icon-go-to-original"></i><span class="sr-only">Go to figure location within the article</span></a></div><div data-visible-on="graphic table"><a href="#" class="core-fv__download_figure  core-fv__btn" title="Download figure"><i aria-hidden="true" class="icon-Icon_Download"></i><span class="sr-only">Download figure</span></a></div><div data-visible-on="graphic table media"><button role="button" class="core-fv__share  core-fv__btn" aria-controls="core-fv__share" aria-expanded="false" title="Toggle share panel"><i aria-hidden="true" class="icon-Icon_Share"></i><span class="sr-only">Toggle share panel</span></button><div id="core-fv__share" aria-label="share pane options" aria-hidden="true" class="core-fv__aside__share core-fv-hidden"><div class="core-fv__panel__header"></div><div class="core-fv__panel__content"><div class="core-fv__panel__title">Share on social media</div><div class="core-fv__panel__text"></div></div></div></div><div data-visible-on="graphic table media"><button role="button" class="core-fv__info  core-fv__btn" aria-controls="core-fv__info" aria-expanded="false" title="Toggle information panel"><i aria-hidden="true" class="icon-Icon_Information"></i><span class="sr-only">Toggle information panel</span></button><div id="core-fv__info" aria-label="info pane options" aria-hidden="true" class="core-fv__aside__info core-fv-hidden"><div class="core-fv__panel__header"></div><div class="core-fv__panel__content"><div class="core-fv__panel__title"></div><div class="core-fv__panel__text"></div></div></div></div></div></header><div class="core-fv__content"><div data-type="graphic" aria-roledescription="carousel"><button type="button" disabled="disabled" title="Go to previous graphic" data-type="graphic" class="core-fv-carousel_control previous"><i aria-hidden="true" class="icon-arrow_l"></i><span class="sr-only"></span></button><div id="core-fv-carousel_graphic" aria-live="polite" aria-atomic="false" aria-label="Displayed graphic" class="core-fv-carousel"></div><button type="button" disabled="disabled" title="Go to next graphic" data-type="graphic" class="core-fv-carousel_control next"><i aria-hidden="true" class="icon-arrow_r"></i><span class="sr-only"></span></button></div><div data-type="table" aria-roledescription="carousel"><button type="button" disabled="disabled" title="Go to previous table" data-type="table" class="core-fv-carousel_control previous"><i aria-hidden="true" class="icon-arrow_l"></i><span class="sr-only"></span></button><div id="core-fv-carousel_table" aria-live="polite" aria-atomic="false" aria-label="Displayed table" class="core-fv-carousel"></div><button type="button" disabled="disabled" title="Go to next table" data-type="table" class="core-fv-carousel_control next"><i aria-hidden="true" class="icon-arrow_r"></i><span class="sr-only"></span></button></div></div><div class="core-fv__filmstrip core-fv-hidden"><button title="View all" aria-expanded="false" aria-controls="core-fv__filmstrip" class="core-fv__filmstrip__tongue core-fv__btn"><svg width="207" height="42" viewBox="0 0 207 42"><path d="M12.8047 15.6552C15.3472 6.58442 23.4524 0 32.8728 0H173.948C183.449 0 191.605 6.70676 194.473 15.7651C197.306 24.7106 201.527 35.4036 207 42H0C4.49018 42 9.45851 27.5933 12.8047 15.6552Z" fill="#f0f0f0"></path><text x="50%" y="28" text-anchor="middle" data-type="graphic"><tspan class="icon-in-svg">&#xe96a;</tspan><tspan dx="10" dy="-4" class="text-in-svg">All figures</tspan></text><text x="50%" y="28" text-anchor="middle" data-type="table"><tspan class="icon-in-svg">&#xe904;</tspan><tspan dx="10" dy="-4" class="text-in-svg">All tables</tspan></text></svg></button><div id="core-fv__filmstrip"><nav aria-label="Figure Viewer extra controls" data-type="graphic" class="core-fv__filmstrip__content"><div class="core-fv__filmstrip__nav"><button type="button" disabled="disabled" title="Go to previous graphic" data-type="graphic" class="core-fv-carousel_control previous"><i aria-hidden="true" class="icon-arrow_l"></i><span class="sr-only"></span></button><div id="core-fv-filmstrip_graphic" aria-live="polite" aria-label="Figure Navigation" role="tablist" class="figures-group"></div><button type="button" disabled="disabled" title="Go to next graphic" data-type="graphic" class="core-fv-carousel_control next"><i aria-hidden="true" class="icon-arrow_r"></i><span class="sr-only"></span></button><button data-target="core-fv-panel_graphic" data-open="viewer" title="Go to all figures directory" aria-controls="core-fv-panel_graphic" class="core-fv__openDirectory"><i aria-hidden="true" class="icon-grid-3"></i><span>All figures</span></button></div></nav><nav aria-label="Figure Viewer extra controls" data-type="table" class="core-fv__filmstrip__content"><div class="core-fv__filmstrip__nav"><button type="button" disabled="disabled" title="Go to previous table" data-type="table" class="core-fv-carousel_control previous"><i aria-hidden="true" class="icon-arrow_l"></i><span class="sr-only"></span></button><div id="core-fv-filmstrip_table" aria-live="polite" aria-label="Figure Navigation" role="tablist" class="figures-group"></div><button type="button" disabled="disabled" title="Go to next table" data-type="table" class="core-fv-carousel_control next"><i aria-hidden="true" class="icon-arrow_r"></i><span class="sr-only"></span></button><button data-target="core-fv-panel_table" data-open="viewer" title="Go to all figures directory" aria-controls="core-fv-panel_table" class="core-fv__openDirectory"><i aria-hidden="true" class="icon-grid-3"></i><span>All tables</span></button></div></nav></div></div></div></div></template><template id="toCitationLink" data-citation="xrefBack.types.citation" data-footnote="xrefBack.types.footnote"><div class="to-citation__wrapper"><a class="to-citation"><i aria-hidden="true" class="icon-subdirectory_arrow_left"></i><span>xrefBack.goTo</span></a></div></template><template id="toCitationButton" data-citation="xrefBack.types.citation" data-footnote="xrefBack.types.footnote"><div class="to-citation__wrapper"><button class="to-citation"><i aria-hidden="true" class="icon-subdirectory_arrow_left"></i><span>xrefBack.goTo</span></button></div></template><template id="toCitationAccordion" data-collapse-citation="xrefBack.types.hideCitation" data-expand-citation="xrefBack.types.showCitation" data-collapse-footnote="xrefBack.types.hideFootnote" data-expand-footnote="xrefBack.types.showFootnote"><div class="to-citation__wrapper"><button aria-controls="aria-controls" aria-expanded="false" aria-label="xrefBack.ariaLabel" class="to-citation__toggle"><i aria-hidden="true" class="icon-plus-light"></i><span data-expand-title="data-expand-title" data-collapsed-title="data-collapsed-title" class="accordion__toggle__title"></span></button><div role="menu" aria-label="xrefBack.links" class="to-citation__accordion no-separator"><ul></ul></div></div></template><template id="toCitationAccordionItem"><li><a class="to-citation"><i aria-hidden="true" class="icon-subdirectory_arrow_left"></i><span></span></a></li></template><template id="collateral_texts_template" data-references="References" data-more="More"><span>Request permissions</span></template><template id="collapsible_authors_template"><button aria-expanded="false" data-expandable="all" data-label-expand="Expand All" data-label-collapse="Collapse All" class="collateral-contributors-control"><span>Expand All</span></button></template>
<template id="collapsible_tables_collapse_template"><div class="collapsible-figure-btn__wrapper expanded"><button aria-expanded="true" class="btn collapsible-figure-btn btn--inverse"><i aria-hidden="true" class="icon-arrow-up"></i><span class="text-uppercase">Collapse</span></button></div></template>
<template id="collapsible_tables_expand_template"><div class="collapsible-figure-btn__wrapper collapsed"><button aria-expanded="false" class="btn collapsible-figure-btn btn--inverse"><i aria-hidden="true" class="icon-arrow-down"></i><span class="text-uppercase">Expand Table</span></button></div></template>
<template id="citations_truncate_template"><div class="truncation-wrapper"><button data-label-expand="Show all references" data-label-collapse="Show fewer references" data-label-remaining="references remaining" data-trigger="collapse" class="btn btn--inverse">Show all references</button></div></template><template id="coreProducts_truncate_template"><div class="truncation-wrapper"><button data-label-expand="SHOW ALL BOOKS" data-label-collapse="Show fewer references" data-label-remaining="books remaining" data-trigger="collapse" class="btn btn--inverse">SHOW ALL BOOKS</button></div></template><template id="authorsAffiliationsLink"><a href="#tab-contributors" class="to-authors-affiliations">Authors Info & Affiliations</a></template><div class="core-collateral"></div>




        
        <div class="separated-block--dashed align-center"><a href="/doi/proceedings/10.1145/3706599" class="btn btn--inverse big">View Table of Contents</a></div>
</main>

        </div>
    


                    
                        



        
        <footer class="footer">



        
        <h2 class="sr-only" tabindex="0">Footer</h2>




        
        <div class="back-to-top clearfix">
    <i class="icon-arrow_u_p"></i>
</div>




        
        <div class="footer-top">









    
    
        <div data-widget-def="ux3-layout-widget" data-widget-id="81a18a14-d709-41fd-9bb6-25a7fc1e13df" class="container">
        



        
        <div class="row sitemap">



        
        <div class="col-sm-2 col-xs-6 sitemap__column">









    
    
        <div data-widget-def="UX3HTMLWidget" data-widget-id="5b00ef28-f63b-4518-bd06-da82035f86ca" class="sitemap__data">
        



        
        <h3 style="font-size: .875rem; margin-bottom: 18px;" tabindex="0">Categories</h3>
<ul class="rlist">
    <li><a href="/journals" title="Browse a listing of ACM’s Journals">Journals</a></li>
    <li><a href="/magazines" title="Browse ACM's Magazines">Magazines</a></li>
    <li><a href="/acmbooks" title="Browse new Releases of ACM Books">Books</a></li>
    <li><a href="/proceedings" title="Browse the ACM Proceedings">Proceedings</a></li>
    <li><a href="/sigs" title="Browse the Special Interest Groups">SIGs</a></li>
    <li><a href="/conferences" title="Browse the Conferences">Conferences</a></li>
    <li><a href="/collections" title="Browse the Special Collections">Collections</a></li>
    <li><a href="/people" title="Discover ACM’s community of authors">People</a></li>
</ul>

        </div>
    

</div><div class="col-sm-4 col-xs-6 sitemap__column">









    
    
        <div data-widget-def="UX3HTMLWidget" data-widget-id="731f98d3-e996-490d-a071-e9b966b32e2d" class="sitemap__data">
        



        
        <h3 style="font-size: .875rem; margin-bottom: 18px;" tabindex="0">About</h3>
<ul class="rlist">
    <li><a href="/about">About ACM Digital Library</a></li>
    <li><a href="/about/dlboard" title="ACM DL Board - Governance and Support Staff">ACM Digital Library Board</a></li>
    <li><a href="/about/access" title="Accessing the DL">Subscription Information</a></li>
    <li><a href="https://www.acm.org/publications/authors/information-for-authors" title="Information for Authors">Author Guidelines</a></li>
    <li><a href="/about/access" title="Accessing the DL">Using ACM Digital Library</a></li>
    <li><a href="/about/content#sec2">All Holdings within the ACM Digital Library</a></li>
    <li><a href="/ccs" title="Classify publications using ACM's Computing Classification System">ACM Computing Classification System</a></li>
     <li><a href="/about/accessibility" title="Digital Library Accessibility">Accessibility Statement</a></li>
</ul>

        </div>
    

</div><div class="col-sm-3 col-xs-6 sitemap__column">









    
    
        <div data-widget-def="UX3HTMLWidget" data-widget-id="d4ed040d-22e8-481c-a7ef-0cac141f5246" class="sitemap__data">
        



        
        <h3 style="font-size: .875rem; margin-bottom: 18px;" tabindex="0">Join</h3>
<ul class="rlist">
    <li><a href="https://www.acm.org/membership/join">Join ACM</a></li>
    <li><a href="https://www.acm.org/special-interest-groups/join">Join SIGs</a></li>
    <li><a href="https://www.acm.org/publications/subscribe">Subscribe to Publications</a></li>
    <li><a href="https://libraries.acm.org/">Institutions and Libraries</a></li>
</ul>

        </div>
    

</div><div class="col-sm-3 col-xs-6 sitemap__column">









    
    
        <div data-widget-def="UX3HTMLWidget" data-widget-id="4a649bf1-cf3f-472c-b764-dc3ab0cf4310" class="sitemap__data">
        



        
        <h3 style="font-size: .875rem; margin-bottom: 18px;" tabindex="0">Connect</h3>
<ul class="rlist social-media__connect">
    <li><a href="/cdn-cgi/l/email-protection#583c34752c3d393518302976393b3576372a3f"><i class="icon-Icon_mail" aria-hidden="true"></i><span>Contact us via email</span></a></li>
    <li><a href="https://www.facebook.com/AssociationForComputingMachinery/"><i class="icon-facebook" aria-hidden="true"></i><span>ACM on Facebook</span></a></li>
    <li><a href="https://x.com/acmdl"><i class="icon-x" aria-hidden="true"></i><span>ACM DL on X</span></a></li>
    <li><a href="https://www.linkedin.com/company/association-for-computing-machinery/"><i class="icon-linkedin" aria-hidden="true"></i><span>ACM on Linkedin</span></a></li>
    <!--li><a href="#" title="icon-Rss"><i class="icon-Rss" aria-hidden="true"></i><span>RSS</span></a></li-->
    <li><a onclick="srv.openModal(true,'02b075ed48492ef0e7598ddf9762f5ef668d7320')"><i class="icon-Icon_Information" aria-hidden="true"></i><span>Send Feedback</span></a></li>
    <li><a onclick="srv.openModal(true,'02b075ed48492ef0e7598ddf9762f5ef668d7320')"><i class="icon-Icon_Information" aria-hidden="true"></i><span>Submit a Bug Report</span></a></li>
</ul>

        </div>
    

</div>
</div>

        </div>
    

</div>










    
    
        <div data-widget-def="ux3-layout-widget" data-widget-id="6e6da9b7-371e-4ea0-827e-8de5915b8cd5" class="footer-bottom text-onDark">
        



        
        <div class="container"><div class="row"><div class="col-md-8 col-sm-6 footer__copyright-wrapper">



        
        <div class="copyright">The ACM Digital Library is published by the Association for Computing Machinery. Copyright © 2025 ACM, Inc.</div>
<ul class="rlist--inline">
    <li><a class="link-nocolor-nounderline" href="https://libraries.acm.org/digital-library/policies#anchor3">Terms of Usage</a></li>
    <li><a class="link-nocolor-nounderline" href="https://www.acm.org/about-acm/privacy-policy">Privacy Policy</a></li>
    <li><a class="link-nocolor-nounderline" href="https://www.acm.org/code-of-ethics">Code of Ethics</a></li>
</ul>
</div><div class="col-md-4 col-sm-6 footer__logos-wrapper">



        
        <div class="logos">









    
    
        <div data-widget-def="ux3-general-image" data-widget-id="42d543b3-ff9d-4f92-bf03-6d1fa00da8c6" class="footer__logo1">
        



        
        <a href="/" title=""><img id="" alt="ACM Digital Library home" src="/specs/products/acm/releasedAssets/images/acm-logo-dl-8437178134fce530bc785276fc316cbf.png" loading="eager"/></a>

        </div>
    











    
    
        <div data-widget-def="ux3-general-image" data-widget-id="5a0bc5df-cd95-408f-8ae5-8b1f40746519" class="footer__logo2">
        



        
        <a href="https://www.acm.org" title="external site link"><img id="" alt="ACM Association for Computing Machinery corporate logo" src="/specs/products/acm/releasedAssets/images/acm-logo-3-10aed79f3a6c95ddb67053b599f029af.png" loading="eager"/></a>

        </div>
    

</div>
</div></div></div>

        </div>
    





        
        <!-- Mopinion Pastea.se  start --><script data-cfasync="false" src="/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script type="text/javascript" nonce="99b3745a0064e879-SJC">(function(){var id="7zt4vp6rxi2bbpxuy9yzabob4fy2enwmumr";var js=document.createElement("script");var pbBtn=document.querySelector('.admin-bar-disclosure');if(!window.PB){js.setAttribute("src","//deploy.mopinion.com/js/pastease.js");document.getElementsByTagName("head")[0].appendChild(js);var t=setInterval(function(){try{new Pastease.load(id);clearInterval(t)}catch(e){}},50)}})();
    </script><!-- Mopinion Pastea.se end -->
</footer>

                    
                        



        
        <script type="text/javascript" nonce="99b3745a0064e879-SJC">
(function(h,o,t,j,a,r){
    h.hj=h.hj||function()
    
    {(h.hj.q=h.hj.q||[]).push(arguments)}
    ;
    h._hjSettings={hjid:1290436,hjsv:6};
    a=o.getElementsByTagName('head')[0];
    r=o.createElement('script');r.async=1;
    r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;
    a.appendChild(r);
})(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');
</script>

                    
                        



        
        <script type="text/javascript" nonce="99b3745a0064e879-SJC">
    (function (w, d) {
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script");
    var v = !("IntersectionObserver" in w) ? "8.17.0" : "10.19.0";
    s.async = true; // This includes the script as async. See the "recipes" section for more information about async loading of LazyLoad.
    s.src = "https://cdn.jsdelivr.net/npm/vanilla-lazyload@" + v + "/dist/lazyload.min.js";
    w.lazyLoadOptions = {elements_selector: ".lazy", "class_loaded": "image-lazy-loaded"};
    b.appendChild(s);
}(window, document));
</script>

                    
                        



        
        <div role="region" aria-label="notification" class="affs-popup"><input id="deleteCookie" type="hidden" name="deleteCookie" value="true"/></div>

                    
                        



        
        <div id="exportDownloadNotReady" role="region" aria-label="notification" class="searchCiteExport-popup hidden"><div class="searchCiteExport-popup__header"><i aria-hidden="true" class="icon-info"></i><span aria-label="Your Search Results Download Request" class="searchCiteExport-popup__title">Your Search Results Download Request</span><i aria-hidden="true" tabindex="0" class="icon-cancel-bold"> </i></div><div aria-label="Search Results Popup Body" class="searchCiteExport-popup__body clearfix"><p>We are preparing your search results for download ...</p><p>We will inform you here when the file is ready.</p><a href="#" disabled="disabled" class="btn blue pull-right">Download now!</a></div></div><div id="exportDownloadReady" role="region" aria-label="notification" class="searchCiteExport-popup hidden"><div class="searchCiteExport-popup__header"><i aria-hidden="true" class="icon-info"></i><span aria-label="Your Search Results Download Request" class="searchCiteExport-popup__title">Your Search Results Download Request</span><i aria-hidden="true" tabindex="0" class="icon-cancel-bold"></i></div><div aria-label="Search Results Popup Body" class="searchCiteExport-popup__body clearfix"><div class="csl-all-response hidden"></div><p>Your file of search results citations is now ready.</p><a href="#" class="btn blue searchCiteExport-popup__close pull-right">Download now!</a></div></div><div id="exportDownloadExpired" role="region" aria-label="notification" class="searchCiteExport-popup hidden"><div class="searchCiteExport-popup__header"><i aria-hidden="true" class="icon-info"></i><span aria-label="Your Search Results Download Request" class="searchCiteExport-popup__title">Your Search Results Download Request</span><i aria-hidden="true" tabindex="0" class="icon-cancel-bold"></i></div><div aria-label="Search Results Popup Body" class="searchCiteExport-popup__body clearfix"><p>Your search export query has expired. Please try again.</p></div></div>

                    
                        



        
        



    

    

    
        
    



                    
                        



        
        

                    
                        
                    
                
            </div>
        </div>
        


    <script nonce="99b3745a0064e879-SJC">if (typeof define !== 'undefined' && define.amd)
    define.amd = false</script><script src="/products/acm/releasedAssets/js/main.bundle-6a226080782392262213.js" nonce="99b3745a0064e879-SJC"></script><script nonce="99b3745a0064e879-SJC">(function (w, d) {
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script");
    var v = !("IntersectionObserver" in w) ? "8.17.0" : "10.19.0";
    s.async = true; // This includes the script as async. See the "recipes" section for more information about async loading of LazyLoad.
    s.src = "https://cdn.jsdelivr.net/npm/vanilla-lazyload@" + v + "/dist/lazyload.min.js";
    w.lazyLoadOptions = {elements_selector: ".lazy", "class_loaded": "image-lazy-loaded"};
    b.appendChild(s);
}(window, document));</script>
    <script type="text/javascript" src="/wro/69be78994216170e0b1c65701457fa99206d6633~product.js" nonce="99b3745a0064e879-SJC"></script>
    



























    

    
    

    
    
    
    
        
            
                <script type="text/javascript" src="/wro/69be78994216170e0b1c65701457fa99206d6633~article-metrics.js" nonce="99b3745a0064e879-SJC"></script>
            
            
            
        
    




<script type="text/javascript" src="/wro/69be78994216170e0b1c65701457fa99206d6633~full-text-analytics.js" nonce="99b3745a0064e879-SJC"></script>





    


            <script defer src="https://static.cloudflareinsights.com/beacon.min.js/vcd15cbe7772f49c399c6a5babf22c1241717689176015" integrity="sha512-ZpsOmlRQV6y907TI0dKBHq9Md29nnaEIPlkf84rnaERnq6zvWvPUqr2ft8M1aS28oN72PdrCzSjY4U6VaAw1EQ==" data-cf-beacon='{"rayId":"99b37459ef3403cc","serverTiming":{"name":{"cfExtPri":true,"cfEdge":true,"cfOrigin":true,"cfL4":true,"cfSpeedBrain":true,"cfCacheStatus":true}},"version":"2025.9.1","token":"b7f168b3cd354a55a4dd51b513830799"}' crossorigin="anonymous"></script>
</body>
        
        
    

</html>